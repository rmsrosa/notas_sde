<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Variação ilimitada dos caminhos amostrais</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações diferenciais aleatórias e estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_browniano">1.3. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_einstein">1.4. O modelo de Einstein para o movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/passeioaleatorio_movbrowniano">1.5. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_bachelier">1.6. O modelo de Bachelier para o mercado de opções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.7. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/simulacoes_intro">1.8. Simulações numéricas de modelos de crescimento natural</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/prob_condicionada">2.5. Probabilidade condicionada</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades fundamentais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/transformacoes">2.8. Transformações de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/convergencias">2.9. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/borel_cantelli">2.10. Lema de Borel-Cantelli</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.11. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. O método de Monte-Carlo</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/monte_carlo">3.1. O método de Monte-Carlo no estudo de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/histograma">3.2. Histograma - estimando a distribuição de probabilidades</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/gerando_num_aleatorios">3.3. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/definicao_pe">4.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_discretos">4.2. Processos em tempos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_continuos">4.3. Processos em tempos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/tipos_processos">4.4. Classes de processos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/filtracao">4.5. Filtração</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/cadeias_markov">4.6. Processos de Markov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/continuity_kolmogorov">4.7. Teorema de Continuidade de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li>5. Processos de Wiener</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/definicao_processo_wiener">5.1. Definição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/existencia_processo_wiener">5.2. Existência de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/propriedades_wiener">5.3. Propriedades de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/ruido_branco">5.4. Relação com ruído branco</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/simetrias_wiener">5.5. Simetrias de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/naodiferenciabilidade_wiener">5.6. Não diferenciabilidade quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/variacao_ilimitada_wiener">5.7. Variação ilimitada dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/c06/integracao_estocastica">6. Integração estocástica</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemann">6.1. Integrais de Riemann</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemannstieltjes">6.2. Integrais de Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_dualidade">6.3. Integrais via dualidade</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/riemann_wiener">6.4. Limites de somatórios à la Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito">6.5. Integral de Itô via processos uniformemente contínuos em média quadrática</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito_l2">6.6. Integral de Itô via processos do tipo escada</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito_propriedades">6.7. Propriedades da integral de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/formula_ito">6.8. Fórmula de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_stratonovich">6.9. Integral de Stratonovich</a></li>
    </div>
    <div class="menu-level-1">
    <li>7. Equações diferenciais aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/existence_solutions_rde">7.1. Existência e unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/basic_examples_rde">7.2. Exemplos básicos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/logistic_rde">7.3. Equação logística aleatória</a></li>
    </div>
    <div class="menu-level-1">
    <li>8. Equações diferenciais estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/setting">8.1. Interpretação da equação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde_particulares">8.2. Existência de soluções locais em casos particulares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde">8.3. Existência de soluções globais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/unicidade_sol_sde">8.4. Unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/continuidade_caminhos">8.5. Limitação e continuidade das soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/linear_sde">8.6. Resolução de equações lineares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/geometric_brownian">8.7. Movimento Browniano geométrico e o preço de ações</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/brownian_bridge">8.8. Ponte Browniana</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/ornstein_uhlenbeck">8.9. A equação de Langevin e o processo de Ornstein-Uhlenbeck</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/ou_aproxima_ruidobranco">8.10. O processo de Ornstein-Uhlenbeck como aproximação de um ruído branco</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/asymptotic_stability">8.11. Estabilidade assintótica</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/relacoes_rode_sde">8.12. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>9. Evolução da função densidade de probabilidade</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/deterministic">9.1. Equação do transporte para equações diferenciais ordinárias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/stochastic">9.2. Equação de Fokker-Planck para equações diferenciais estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/stationaryOU">9.3. Distribuição assintótica estacionária dos processos de Ornstein-Uhlenbeck</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/feynmann_kac">9.4. Fórmula de Feynman-Kac e a equação retrógrada de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li>10. Métodos numéricos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/tx_convergencia">10.1. Convergências forte e fraca</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_wiener">10.2. Simulações de processos de Wiener e browniano geométrico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/convergencia_euler_maruyama">10.3. Convergência forte do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/nao_convergencia_euler_maruyama">10.4. Não convergência do método de Euler-Maruyama sem condição Lipschitz global</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_convergencia_em">10.5. Simulações ilustrando ordem de  convergência do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/heun">10.6. Método de Heun</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_convergencia_randomheun">10.7. Simulações ilustrando ordem de convergência do método de Heun para equações diferenciais aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/milstein">10.8. O método de Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_milstein">10.9. Simulações Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/convergencia_fraca_em">10.10. Convergência fraca do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/sciml">10.11. O ambiente SciML da linguagem Julia</a></li>
    </div>
    <div class="menu-level-1">
    <li>11. Sistemas de equações aleatórias</li>
    </div>
    <div class="menu-level-1">
    <li>12. Sistemas de equações estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/nuclear_reactions">12.1. Reações nucleares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir">12.2. Modelo SIR estocástico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir_network">12.3. Modelo SIR estocástico estruturado em rede</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_extension_kolmogorov">Teorema de Extensão de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c05/naodiferenciabilidade_wiener">5.6. Não diferenciabilidade quase sempre dos caminhos amostrais <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c06/integracao_estocastica"><kbd>→</kbd> 6. Integração estocástica</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">5.7. Variação ilimitada dos caminhos amostrais</a></h1>
<p>Uma característica fundamental dos processos de Wiener é a de que os seus caminhos amostrais são, quase certamente, de <em>variação ilimitada.</em> Por esse motivo precisamos de conceitos diferentes de integração para dar sentido às equações estocásticas &#40;as integrais de Itô e de Stratonovich&#41;. Caso contrário, usaríamos o conceito de <em>integral de Riemann-Stieltjes.</em></p>
<p>Vejamos, abaixo, esses conceitos de variação limitada/ilimitada e de integral de Riemann-Stieltjes e o fato dos caminhos amostrais de um processo de Wiener serem, quase certamente, de variação ilimitada.</p>
<h2 id="funções_de_variação_limitada_ou_ilimitada"><a href="#funções_de_variação_limitada_ou_ilimitada" class="header-anchor">Funções de variação limitada ou ilimitada</a></h2>
<p>Se \(g = g(t)\) representa a posição de um objeto ao longo do tempo, definida em um intervalo temporal \([a, b],\) com \(a < b,\) a distância entre o ponto inicial e o ponto final é simplesmente \(|g(b) - g(a)|.\) Mas, ao longo do caminho, o objeto pode ir para frente e para trás diversas vezes, como em um <em>zig-zag.</em> Nesse caso, podemos estimar a distância percorrida calculando</p>
\[
\sum_{j=1}^n |g(t_j) - g(t_{j-1})|
\]
<p>para instantes de tempo \(a \leq t_0 < t_1 < \ldots < t_n \leq b.\) Caso \(x\) seja continuamente diferenciável, isso pode ser estimado por</p>
\[
\sum_{j=1}^n |g(t_j) - g(t_{j-1})| \leq \sum_{j=1}^n |g'(\theta_j)|\Delta t_j \leq \max\{|g'|\}(b-a), 
\]
<p>onde \(t_{j-1} \leq \theta_j \leq t_j\) e \(\Delta t_j = t_j - t_{j-1}.\) Observe que a estimativa à direita independe da malha de tempo, de modo que</p>
\[
\sup_{0\leq t_0 < t_1 < \ldots t_n \leq T}\sum_{j=1}^n |g(t_j) - g(t_{j-1})| \leq \max_{[a, b]}\{|g'|\}(b-a),
\]
<p>onde o supremo é tomado em relação à todas as partições possíveis do intervalo \([a, b].\)</p>
<p>Na verdade, podemos ser mais precisos em relação à distância percorrida. Sendo \(g\) continuamente diferenciável, a soma</p>
\[
\sum_{j=1}^n |g'(\theta_j)|\Delta t_j
\]
<p>é, de fato, uma soma de Riemman, cujo limite é a integral</p>
\[
\int_a^b |g'(t)| \;\mathrm{d}t.
\]
<p>Voltando à estimativa relativa a uma partição arbitrária, caso a função seja Lipschitz contínua em \([a, b],\) com constante de Lipschitz \(L \geq 0,\) ainda podemos limitar essa quantidade:</p>
\[
\sup_{a\leq t_0 < t_1 < \ldots t_n \leq b}\sum_{j=1}^n |g(t_j) - g(t_{j-1})| \leq L(b-a).
\]
<p>Mas podemos ter \(g\) sem ser Lipschitz contínua e, ainda assim, essa quantidade ser limitada. Mesmo certas funções descontínuas são de variação limitada. Por exemplo, \(g(t) = \chi_{[0,1]}(t)\) &#40;vale \(1\) no intervalo \([0, 1]\) e vale \(0\) fora do intervalo&#41; é de variação limitada. Em particular, qualquer função monótona limitada é de variação limitada. Funções de distribuição acumulada de probabilidade são monótonas não decrescentes e de variação limitada.</p>
<p>Essa quantidade é chamada de <strong>variação</strong> da função no intervalo \([a, b]\) e é denotada por \(V(g; a, b)\):</p>
\[
\mathrm{V}(g; a, b) = \sup_{a\leq t_0 < t_1 < \ldots t_n \leq b}\sum_{j=1}^n |g(t_j) - g(t_{j-1})|.
\]
<p>Caso \(V(g; a, b)\) seja finito, dizemos que a função é de <strong>variação limitada,</strong> no intervalo \([a, b].\) Caso contrário, ela é dita de <strong>variação ilimitada.</strong></p>
<h2 id="integral_de_riemann-stieltjes"><a href="#integral_de_riemann-stieltjes" class="header-anchor">Integral de Riemann-Stieltjes</a></h2>
<p>Funções de variação limitada são úteis para se estender a integral de Riemann para a chamada <em>integral de Riemann-Stieltjes:</em></p>
\[
\int_a^b f(t)\;\mathrm{d}g(t) = \lim \sum_{j=1}^n f(\theta_i) (g(t_j) - g(t_{j-1})).
\]
<p>O limite é tomado em relação ao refinamento das malhas: \(\max_j\{t_j - t_{j-1}\} \rightarrow 0.\) Desde que \(g\) seja de variação limitada, é possível mostrar que o limite converge, quando \(f\) é contínua. Obtemos a integral de Riemann ao tomarmos \(g(t) = t.\)</p>
<p>Como a função de probabilidade acumulada \(g(x) = \mathbb{P}(X \leq x)\) de uma variável aleatória \(X\) é monónota e limitada, ela é de variação limitada, de modo que podemos representar a esperança de uma nova variável \(Y = h(X)\) através de uma integral de Riemann-Stieltjes:</p>
\[
\mathbb{E}(h(X)) = \int_\mathbb{R} h(x) \;\mathrm{d}g(x).
\]
<p>Caso \(g\) seja diferenciável, então \(\mathrm{d}g = f\mathrm{d}x,\) onde \(f\) é a função de densidade de probabilidade. Mas a integral acima independe de \(g\) ser diferenciável ou não.</p>
<p>A integral de Riemann-Stieltjes possui diversas propriedades análogas à da integral de Riemann, como linearidade:</p>
\[
\int_a^b (\lambda_1 f_1(t) + \lambda_2 f_2(t))\;\mathrm{d}g(t) = \lambda_1 \int_a^b f_1(t)\;\mathrm{d}g(t) + \lambda_2 \int_a^b f_2(t)\;\mathrm{d}g(t).
\]
<p>Também podemos concatenar integrais</p>
\[
\int_a^b f(t)\;\mathrm{d}g(t) + \int_b^c f(t)\;\mathrm{d}g(t) = \int_a^c f(t)\;\mathrm{d}g(t),
\]
<p>independentemente da ordem de \(a, b, c.\)</p>
<p>Mas a integral de Riemann-Stieltjes não é positiva, i.e.</p>
\[
\int_a^b f(t)\;\mathrm{d}g(t)
\]
<p>pode ser negativa, mesmo que \(f\geq 0.\) Para ver isso, basta considerar \(g(t) = -t.\) Isso nos impede de estimar a integral de uma função em termos da integral de outra função que a limite.</p>
<p>Veremos que algo parecido ocorre com a integral de Itô.</p>
<h2 id="caminhos_amostrais_de_processos_de_wiener"><a href="#caminhos_amostrais_de_processos_de_wiener" class="header-anchor">Caminhos amostrais de processos de Wiener</a></h2>
<p>Vamos, agora, mostrar essa propriedade fundamental de processos de Wiener que é a de que os seus caminhos amostrais, em qualquer intervalo \([0, T],\) \(T > 0,\) são, quase certamente, de variação ilimitada.</p>
<p>Queremos, para isso, estimar a variação</p>
\[
\mathrm{V}(W_t; 0, T) = \sup_{0\leq t_0 < t_1 < \ldots t_n \leq T}\sum_{j=1}^n |W_{t_j} - W_{t_{j-1}}|.
\]
<p>A ideia é considerar uma estimativa por baixo para mostrar que essa variação é ilimitada. Sejam, então, \(0 = t_0 < t_1 < \ldots < t_n = T.\) Temos</p>
\[
\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2 \leq \left(\max_{j=1, \ldots, n} |W_{t_j} - W_{t_{j-1}}|\right)\sum_{j=1}^n |W_{t_j} - W_{t_{j-1}}|.
\]
<p>Para efeito de contradição, vamos assumir que a malha seja uniforme e em pontos diádicos, i.e. para cada \(k\in \mathbb{N},\) tomamos \(n = 2^k,\) \(\tau = T/n = T/2^k\) e \(t_j = j\tau=j/2^k,\) para \(j = 0, \ldots, n.\)</p>
<p>Vamos mostrar que, quando \(k \rightarrow \infty,\) o lado esquerdo converge para um valor finito positivo e o primeiro termo do lado direito converge para zero, de modo que a variação tem que ser ilimitada.</p>
<p>O fato da malha ser uniforme facilita obtermos expressões mais explícitas para certas quantidades. Por outro lado, o uso dos pontos diádicos nos dá um decrescimento rápido o suficiente que nos permite usar o Lema de Borel-Cantelli. Nenhuma dessas duas condições é necessária. Há outras demonstrações mais delicadas que se aplicam a malhas arbitrárias. Mas o resultado com malhas diádicas é suficiente.</p>
<h3 id="sobre_a_soma_dos_quadrados_dos_incrementos"><a href="#sobre_a_soma_dos_quadrados_dos_incrementos" class="header-anchor">Sobre a soma dos quadrados dos incrementos</a></h3>
<p>Denote a soma dos quadrados dos incrementos por</p>
\[
S_k = \sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2,
\]
<p>lembrando que \(n = 2^k\) e \(t_j = j/2^k.\)</p>
<p>O valor esperado da soma dos quadrados dos incrementos pode ser escrito como</p>
\[
\mathbb{E}\left[S_k\right] = \mathbb{E}\left[\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right] = \sum_{j=1}^n \mathbb{E}\left[\left(W_{t_j} - W_{t_{j-1}}\right)^2\right].
\]
<p>Observe que, usando-se a propriedade \(\mathbb{E}(W_tW_s) = \mathrm{Cov}(W_t, W_s) = \min\{t, s\},\)</p>
\[
\begin{align*}
\mathbb{E}\left[\left(W_{t_j} - W_{t_{j-1}}\right)^2\right] & = \mathbb{E}\left[W_{t_j}^2 - 2W_{t_j}W_{t_{j-1}} + W_{t_{j-1}}^2\right] \\
& = \mathbb{E}\left[W_{t_j}^2\right] -2\mathbb{E}\left[W_{t_j}W_{t_{j-1}}\right] + \mathbb{E}\left[W_{t_{j-1}}^2\right] \\
& = t_j - 2t_{j-1} + t_{j-1} \\
& = t_j - t_{j-1}.
\end{align*}
\]
<p>Assim, obtemos a identidade</p>
\[
\mathbb{E}\left[S_k\right] = \sum_{j=1}^n (t_j - t_{j-1}) = t_n - t_0 = T.
\]
<p>Observe que, aqui, o resultado vale para uma malha arbitrária.</p>
<p>Agora, estimamos a sua variância. Primeiro, temos</p>
\[
\mathbb{E}\left[S_k^2\right] = \mathbb{E}\left[\left(\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right)^2\right] = \sum_{i, j = 1}^n\mathbb{E}\left[\left(W_{t_i} - W_{t_{i-1}}\right)^2\left(W_{t_j} - W_{t_{j-1}}\right)^2\right]
\]
<p>Para \(i\neq j,\) como os incrementos são independentes e normais, temos</p>
\[
\mathbb{E}\left[\left(W_{t_i} - W_{t_{i-1}}\right)^2\left(W_{t_j} - W_{t_{j-1}}\right)^2\right] = \mathbb{E}\left[\left(W_{t_i} - W_{t_{i-1}}\right)^2\right]\mathbb{E}\left[\left(W_{t_j} - W_{t_{j-1}}\right)^2\right] = (t_i - t_{i-1})(t_j - t_{j-1}).
\]
<p>Para \(i = j,\) como o incremento é normal, podemos calcular os seus momentos explicitamente, obtendo, em particular,</p>
\[
\mathbb{E}\left[\left(W_{t_j} - W_{t_{j-1}}\right)^4\right] = 3(t_j - t_{j-1})^2.
\]
<p>Assim,</p>
\[
\begin{align*}
\mathbb{E}\left[\left(\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right)^2\right] & = \sum_{i \neq j = 1}^n (t_i - t_{i-1})(t_j - t_{j-1}) + \sum_{j = 1}^n 3(t_j - t_{j-1})^2 \\
& = \sum_{i, j = 1}^n (t_i - t_{i-1})(t_j - t_{j-1}) + 2\sum_{j = 1}^n (t_j - t_{j-1})^2.
\end{align*}
\]
<p>Os termos do primeiro somatório são separáveis em \(i\) e \(j,\) de modo que</p>
\[
\begin{align*}
\mathbb{E}\left[\left(\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right)^2\right] & = \left(\sum_{i = 1}^n (t_i - t_{i-1})\right)\left(\sum_{j = 1}^n (t_j - t_{j-1})\right) + 2\sum_{j = 1}^n (t_j - t_{j-1})^2 \\
& = T^2 + 2\sum_{j = 1}^n (t_j - t_{j-1})^2.
\end{align*}
\]
<p>Portanto, a variância é dada por</p>
\[
\begin{align*}
\mathrm{Var}\left(\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right) & = \mathbb{E}\left[\left(\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right)^2\right] - \mathbb{E}\left[\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right]^2 \\
& = T^2 + 2\sum_{j = 1}^n (t_j - t_{j-1})^2 - T^2 \\
& = 2\sum_{j = 1}^n (t_j - t_{j-1})^2.
\end{align*}
\]
<p>Podemos estimar</p>
\[
\mathrm{Var}\left(\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right) \leq 2T\max_{j=1,\ldots, n}\{(t_j - t_{j-1})\}.
\]
<p>Novamente, essa estimativa vale para uma malha arbitrária. No caso da malha uniforme, com \(\tau = 1/2^k,\) temos, mais precisamente,</p>
\[
\mathrm{Var}\left(\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2\right) \leq 2T\tau = \frac{T}{2^{k-1}}.
\]
<p>No limite do refinamento da malha, temos</p>
\[
\mathbb{E}[S_k] = T, \quad \mathrm{Var}(S_k) \rightarrow 0,
\]
<p>portanto</p>
\[
S_k \rightarrow T,
\]
<p>quando \(k\rightarrow \infty.\) Mais importante é a estimativa que segue da desigualdade de Chebyshev,</p>
\[
    \mathbb{P}\left(|S_k - T| \geq \varepsilon \right) \leq \mathbb{E}\left[\frac{(S_k - T)^2}{\varepsilon^2}\right] \leq \frac{1}{\varepsilon^2}\frac{T}{2^{k-1}},
\]
<p>para \(\varepsilon>0\) arbitrário. Com isso,</p>
\[
    \sum_{k = 1}^\infty \mathbb{P}\left(|S_{k} - T| \geq \varepsilon \right) \leq \frac{2T}{\varepsilon^2} < \infty.
\]
<p>Portanto, pelo Lema de Borel-Cantelli,</p>
\[
\mathbb{P}\left(\limsup_{k\rightarrow \infty} |S_k - T| \geq \varepsilon\right) = 0.
\]
<p>Como \(\varepsilon > 0\) é arbitrário, segue que</p>
\[
\mathbb{P}\left( \limsup_{k\rightarrow \infty} |S_k - T| > 0 \right) = 0.
\]
<p>Escrito de outra maneira,</p>
\[
\mathbb{P}\left( \lim_{k\rightarrow \infty} |S_k - T| = 0 \right) = 1,
\]
<p>ou seja,</p>
\[
S_{k} \rightarrow T,
\]
<p>quase certamente.</p>
<h3 id="sobre_o_máximo_dos_incrementos"><a href="#sobre_o_máximo_dos_incrementos" class="header-anchor">Sobre o máximo dos incrementos</a></h3>
<p>Por definição, quase todos os caminhos amostrais de um processo de Wiener são contínuos. Como o intervalo \([0, T]\) é fechado e limitado, segue, que, para quase todo \(\omega,\) o caminho amostral \(t \mapsto W_t(\omega)\) é uniformemente contínuo em \([0, T].\)</p>
<p>Assim, dado \(\varepsilon > 0,\) existe \(\delta > 0\) tal que</p>
\[
|W_s(\omega) - W_t(\omega)| < \varepsilon, \qquad \forall t, s\in [0, T), \;|t - s| \leq \delta.
\]
<p>No caso da malha escolhida, temos, para \(\varepsilon > 0\) e \(k \geq \ln (1/\delta),\) que \(t_j - t_{j-1} = 1/n = 1/2^k \leq \delta\) e, portanto,</p>
\[
\max_{j=1, \ldots, n} |W_{t_j} - W_{t_{j-1}}| \leq \delta.
\]
<p>Dessa forma, vemos que</p>
\[
\max_{j=1, \ldots, n} |W_{t_j} - W_{t_{j-1}}| \rightarrow 0, \qquad k \rightarrow \infty,
\]
<p>para quase todo caminho amostral.</p>
<h3 id="variação_ilimitada"><a href="#variação_ilimitada" class="header-anchor">Variação ilimitada</a></h3>
<p>Voltemos, agora, à identidade</p>
\[
\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2 \leq \left(\max_{j=1, \ldots, n} |W_{t_j} - W_{t_{j-1}}|\right)\sum_{j=1}^n |W_{t_j} - W_{t_{j-1}}|.
\]
<p>Obtivemos que, para quase todo caminho amostral, quando a malha é refinada, ao limite \(k\rightarrow \infty,\) o termo do lado esquerdo converge para \(T,\) enquanto que o primeiro termo do lado direito converge para zero. Portanto, devemos ter</p>
\[
\sum_{j=1}^n |W_{t_j} - W_{t_{j-1}}| \geq \frac{\sum_{j=1}^n \left(W_{t_j} - W_{t_{j-1}}\right)^2}{\max_{j=1, \ldots, n} |W_{t_j} - W_{t_{j-1}}|} \rightarrow \infty, \qquad k \rightarrow \infty.
\]
<p>Isso implica, em particular, que, para quase todo caminho amostral, a variação do caminho é ilimitada, i.e.</p>
\[
    \mathbb{P}\left(\mathrm{V}(W_t; 0, T) = \infty\right) = 1.
\]

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c05/naodiferenciabilidade_wiener">5.6. Não diferenciabilidade quase sempre dos caminhos amostrais <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c06/integracao_estocastica"><kbd>→</kbd> 6. Integração estocástica</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: July 20, 2025. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    

  </body>
</html>
