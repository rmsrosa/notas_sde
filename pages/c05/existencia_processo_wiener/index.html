<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Existência de processos de Wiener</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  
    <link rel="stylesheet" href="/notas_sde/libs/highlight/github.min.css">
    <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
    <script src="/notas_sde/libs/highlight/julia.min.js"></script>
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre').forEach((el) => {
          hljs.highlightElement(el);
        });
      });
    </script>
  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações diferenciais aleatórias e estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_browniano">1.3. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_einstein">1.4. O modelo de Einstein para o movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/passeioaleatorio_movbrowniano">1.5. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_bachelier">1.6. O modelo de Bachelier para o mercado de opções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.7. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/simulacoes_intro">1.8. Simulações numéricas de modelos de crescimento natural</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/prob_condicionada">2.5. Probabilidade condicionada</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades fundamentais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/transformacoes">2.8. Transformações de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/convergencias">2.9. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/borel_cantelli">2.10. Lema de Borel-Cantelli</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.11. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. O método de Monte-Carlo</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/monte_carlo">3.1. O método de Monte-Carlo no estudo de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/histograma">3.2. Histograma - estimando a distribuição de probabilidades</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/gerando_num_aleatorios">3.3. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/definicao_pe">4.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_discretos">4.2. Processos em tempos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_continuos">4.3. Processos em tempos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/tipos_processos">4.4. Classes de processos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/filtracao">4.5. Filtração</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/cadeias_markov">4.6. Processos de Markov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/continuity_kolmogorov">4.7. Teorema de Continuidade de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li>5. Processos de Wiener</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/definicao_processo_wiener">5.1. Definição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/existencia_processo_wiener">5.2. Existência de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/propriedades_wiener">5.3. Propriedades de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/ruido_branco">5.4. Relação com ruído branco</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/simetrias_wiener">5.5. Simetrias de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/naodiferenciabilidade_wiener">5.6. Não diferenciabilidade quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/variacao_ilimitada_wiener">5.7. Variação ilimitada dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/c06/integracao_estocastica">6. Integração estocástica</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemann">6.1. Integrais de Riemann</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemannstieltjes">6.2. Integrais de Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_dualidade">6.3. Integrais via dualidade</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/riemann_wiener">6.4. Limites de somatórios à la Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito">6.5. Integral de Itô de processos uniformemente contínuos em média quadrática</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito_l2">6.6. Integral de Itô de processos L²</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito_propriedades">6.7. Propriedades da integral de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/formula_ito">6.8. Fórmula de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_stratonovich">6.9. Integral de Stratonovich</a></li>
    </div>
    <div class="menu-level-1">
    <li>7. Equações diferenciais aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/existence_solutions_rde">7.1. Existência e unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/basic_examples_rde">7.2. Exemplos básicos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/logistic_rde">7.3. Equação logística aleatória</a></li>
    </div>
    <div class="menu-level-1">
    <li>8. Equações diferenciais estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/setting">8.1. Interpretação da equação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde_particulares">8.2. Existência de soluções locais em casos particulares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde">8.3. Existência de soluções globais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/unicidade_sol_sde">8.4. Unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/continuidade_caminhos">8.5. Limitação e continuidade das soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/linear_sde">8.6. Resolução de equações lineares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/geometric_brownian">8.7. Movimento Browniano geométrico e o preço de ações</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/brownian_bridge">8.8. Ponte Browniana</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/ornstein_uhlenbeck">8.9. A equação de Langevin e o processo de Ornstein-Uhlenbeck</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/ou_aproxima_ruidobranco">8.10. O processo de Ornstein-Uhlenbeck como aproximação de um ruído branco</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/asymptotic_stability">8.11. Estabilidade assintótica</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/relacoes_rode_sde">8.12. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>9. Evolução da função densidade de probabilidade</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/deterministic">9.1. Equação do transporte no caso de equações diferenciais ordinárias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/stochastic">9.2. Equação de Fokker-Planck no caso de equações estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/stationaryOU">9.3. Distribuição assintótica estacionária dos processos de Ornstein-Uhlenbeck</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/feynmann_kac">9.4. Fórmula de Feynman-Kac e a equação retrógrada de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li>10. Métodos numéricos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/tx_convergencia">10.1. Convergências forte e fraca</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_wiener">10.2. Simulações de processos de Wiener e browniano geométrico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/convergencia_euler_maruyama">10.3. Convergência forte do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/nao_convergencia_euler_maruyama">10.4. Não convergência do método de Euler-Maruyama sem condição Lipschitz global</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_convergencia_em">10.5. Simulações ilustrando ordem de  convergência do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/heun">10.6. Método de Heun</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_convergencia_randomheun">10.7. Simulações ilustrando ordem de convergência do método de Heun para equações diferenciais aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/milstein">10.8. O método de Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_milstein">10.9. Simulações Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/convergencia_fraca_em">10.10. Convergência fraca do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/sciml">10.11. O ambiente SciML da linguagem Julia</a></li>
    </div>
    <div class="menu-level-1">
    <li>11. Sistemas de equações aleatórias</li>
    </div>
    <div class="menu-level-1">
    <li>12. Sistemas de equações estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/nuclear_reactions">12.1. Reações nucleares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir">12.2. Modelo SIR estocástico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir_network">12.3. Modelo SIR estocástico estruturado em rede</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_extension_kolmogorov">Teorema de Extensão de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c05/definicao_processo_wiener">5.1. Definição <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c05/propriedades_wiener"><kbd>→</kbd> 5.3. Propriedades de processos de Wiener</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">5.2. Existência de processos de Wiener</a></h1>
<p>O tipo de processo conhecido atualmente como processo de Wiener foi introduzido, como modelo para o movimento Browniano, por Norbert Wiener, em 1923, junto com a demonstração de existência de tal processo. A demonstração de Wiener é baseada em uma expansão senoidal a partir da lei de distribuição dos coeficientes de Fourier do processo. Essa expansão é feita no intervalo \([0, 2\pi]\) e toma a forma</p>
\[
    W_t = \frac{t}{\sqrt{2\pi}} Z_0 + \frac{2}{\sqrt{2\pi}}\sum_{n=1}^\infty \frac{\sin(\frac{1}{2}nt)}{n}Z_n, \qquad 0 \leq t \leq 2\pi,
\]
<p>onde \(\{Z_n\}_{n\in\mathbb{N}}\) são normais \(\mathcal{N}(0, 1)\) independentes e identicamente distribuídas. É possível mostrar que essa série converge para um processo de Wiener.</p>
<p>A motivação para a expansão acima vem da derivada ser, pelo menos formalmente, um <em>ruído branco,</em> com os coeficientes da série de mesma amplitude, em um sentido probabilístico. De fato, derivando formalmente a série acima, temos</p>
\[
    \frac{\mathrm{d} W_t}{\mathrm{d}t} = \frac{1}{\sqrt{2\pi}} Z_0 + \frac{1}{\sqrt{2\pi}}\sum_{n=1}^\infty \sin(\frac{1}{2}nt)Z_n, \qquad 0 \leq t \leq 2\pi,
\]
<p>de modo que os coeficientes são normais independentes identicamente distribuídas,</p>
\[
    \frac{1}{\sqrt{2\pi}}Z_n \sim \mathcal{N}\left(0, \frac{1}{2\pi}\right).
\]
<p>Da mesma forma que séries de Fourier de funções determinísticas, expansões em séries senoidas podem ser feitas para outros processos estocásticos, a partir dos trabalhos seguintes de Wiener, em conjunto com Zygmund e Paley e levam, atualmente, o nome de representação de Paley-Wiener.</p>
<p>Outra demonstração possível é via limite de passeios aleatórios devidamente reescalados,</p>
\[
    W_t^{(n)} = \frac{1}{\sqrt{n}}\sum_{1 \leq k \leq nt} Z_k, \qquad 0\leq t \leq 1.
\]
<p>O intervalo \([0, 1]\) é dividido em \(n\) subintervalos de tamanho \(1/n\) e passos \(Z_k/\sqrt{n} \sim \mathcal{N}(0, 1/n)\) são dados a cada subintervalo. Pelo Teorema Central do Limite, para cada \(t,\) as variáveis aleatórias \(W_t^{(n)}\) convergem para \(\mathcal{N}(0, t),\) mas isso não resolve a questão toda, da convergência do processo como um todo e dos passos serem independentes e identicamente distribuídos, com a distribuição correta. Para isso, é preciso explorar certas simetrias do passeio aleatório e usar uma norma apropriada para mostrar a convergência dos caminhos amostrais em um espaço adequado. Esse resultado de que, de fato, esses processos \(\{W_t^{(n)}\}_t,\) \(n\in\mathbb{N},\) convergem para um processo de Wiener é devido a Monroe Donsker &#40;1951, 1952&#41;.</p>
<p>Vamos, no entanto, discutir, a seguir, uma demonstração mais simples, dada por Paul Lévy, e inspirada nas demonstrações apresentadas em Morters &amp; Peres &#40;2010&#41; e Evans &#40;2013&#41;. A demonstração é feita por um processo de limite, a partir de um processo estocástico discreto que é interpolado para um processo contínuo. A construção crucial é feita no intervalo \(I = [0, 1].\) A partir daí, podemos transladar e concatenar processos independentes em \([0, 1]\) para obter um processo de Wiener em \([0, \infty).\)</p>
<p>Veremos duas formas de escrever essa sequência aproximante de processos no intervalo \([0, 1].\) Uma facilita mostrarmos que os incrementos são normais independentes e identicamente distribuídos, enquanto que a outra facilita a demonstração de convergência da sequência.</p>
<p>Vale ressaltar que um processo de Wiener não é único, assim como não há uma única variável aleatória normal. Podemos, naturalmente, ter várias normais, independentes umas das outras. No caso do processo de Wiener, podemos, por exemplo, contruir um processo através do limite de interpolações de diferentes sequências de variáveis normais, obtendo diferentes processos de Wiener.</p>
<h2 id="partição_diádica_do_intervalo_unitário"><a href="#partição_diádica_do_intervalo_unitário" class="header-anchor">Partição diádica do intervalo unitário</a></h2>
<p>A aproximação é feita a partir de malhas formadas por números <em>diádicos</em> &#40;números racionais cujo denominador é uma potência de 2&#41; entre zero e um. Mais precisamente, considere os conjuntos</p>
\[
D_n = \left\{\frac{k}{2^{n-1}}; \; k = 0, 1, \ldots, 2^{n-1}\right\}, \qquad n\in \mathbb{N}.
\]
<p>A união de todos esses pontos é um conjunto enumerável denso no intervalo \([0, 1]\) e é denotada por</p>
\[
D = \cup_{n\in \mathbb{N}} D_n.
\]

<img src="/notas_sde/assets/pages/c05/existencia_processo_wiener/code/output/dyadic_points.svg" alt="">
<h2 id="processo_discreto_iid_e_espaço_amostral"><a href="#processo_discreto_iid_e_espaço_amostral" class="header-anchor">Processo discreto i.i.d. e espaço amostral</a></h2>
<p>Como dito, um processo de Wiener pode ser obtido como limite de processos obtidos por interpolação de um processo discreto i.i.d., que vamos definir em \(D.\)</p>
<p>Com esse fim, considere um processo discreto <em>i.i.d.</em> \(\{Z_d\}_{d\in D\setminus \{0\}},\) onde as variáveis \(Z_d\) são mutuamente independentes e dadas por normais \(Z_d \sim \mathcal{N}(0, 1).\) Como \(D\) é enumerável, podemos considerar o conjunto</p>
\[
\Omega = \mathbb{R}^D
\]
<p>como espaço amostral, e por \(\mathcal{A}\) a \(\sigma\)-álgebra gerada por \(\pi_d^{-1}(\mathcal{B}),\) onde \(\mathcal{B}\) são os conjuntos borelianos em \(\mathbb{R}\) e \(\pi_d : \Omega \rightarrow \mathbb{R}\) são as projeções levam um caminho \(\omega\in \Omega\) no elemento \(\pi_d \omega = \omega(d),\) em \(d\in D.\) Denotamos a medida de probabilidade do processo \(\{Z_d\}_{d\in D\setminus \{0\}}\) por \(\mathbb{P}.\) Para simplificar, escrevemos \(Z_0 = 0,\) já que queremos que o processo de Wiener limite satisfaça \(W_0 = Z_0 = 0.\)</p>
<h2 id="sequência_aproximante_de_processos_discretos"><a href="#sequência_aproximante_de_processos_discretos" class="header-anchor">Sequência aproximante de processos discretos</a></h2>
<p>Vamos primeiro construir uma sequência de processos discretos, cada um com parâmetro em \(D_n,\) \(n\in\mathbb{N}.\) Estes processos serão interpolados para processos em \([0, 1].\) Por motivo de clareza, vamos denotar esses processos discretos por \(\{X_d^{(n)}\}_{d\in D_n}.\) As interpolações contínuas serão denotadas por \(\{W_t^{(n)}\}_{t\in [0, 1]}.\) E, no limite, teremos o processo contínuo \(\{W_t\}_{t\in [0, 1]}.\) Por serem extensões, teremos \(W_d = W_d^{(n)} = X_d^{(n)},\) nos pontos diádicos \(d\in D_n.\) Observe que os processos \(\{X_d^{(n)}\}_{d\in D_n}\) são, na verdade, vetores aleatórios, já que cada \(D_n\) é finito.</p>
<p>Para cada \(d\in D_n,\) esperamos ter \(X_d^{(n)} = W_d = W_d - W_0 \sim \mathcal{N}(0, d).\) Então seria natural pensarmos em definir \(X_d^{(n)}\) como \(Z_d / \sqrt{d},\) já que \(Z_d \sim \mathcal{N}(0, 1),\) de modo que \(Z_d/\sqrt{d} \sim \mathcal{N}(0, d),\) e interpolar, de alguma forma, para \(t\in I \setminus D_n.\) Apesar disso convergir para um processo, este não terá a distribuição correta dos passos. E nem os seus passos serão independentes. Mas uma variação disso funciona. Essa variação se baseia no fato de que se \(A\) e \(B\) são duas variáveis normais independentes com mesma variância, então \(A+B\) e \(A-B\) também são independentes e com o dobro da variância de \(A\) e \(B.\)</p>
<p>Mais precisamente, definimos, para cada \(n\in \mathbb{N},\) o processo discreto \(\{X_d^{(n)}\}_{d\in D_n},\) na malha finita \(D_n,\) da seguinte forma. Primeiramente, sendo \(D_1 = \{0, 1\},\) definimos</p>
\[
X_0^{(1)} = 0, \quad X_1^{(1)} = Z_1.
\]
<p>Para \(n = 2,\) temos \(D_2 = \{0, 1/2, 1\}.\) A ideia é estender \(\{X_d^{(1)}\}_{d\in D_1}\) para um \(\{X_d^{(2)}\}_{d\in D_2},\) em \(D_2\supset D_1,\) mantendo os processos \(X_0^{(1)}, X_1^{(1)}\) em \(d = 0, 1\) e adicionando uma fração de \(Z_{1/2}\) à interpolação linear de \(X_0^{(1)} = 0\) e \(X_1^{(1)} = Z_1,\) em \(d = 1/2.\) Mais precisamente, fazemos</p>
\[
X_0^{(2)} = X_0^{(1)}, \quad X_1^{(2)} = X_1^{(1)}, \quad X_{1/2}^{(2)} = \frac{X_0^{(1)} + X_1^{(1)}}{2} + \frac{Z_{1/2}}{2}.
\]
<p>Agora, continuamos por indução, estendendo o processo \(\{X_d^{(n)}\}_{d\in D_n},\) em \(D_n,\) para um processo \(\{X_d^{(n+1)}\}_{d\in D_{n+1}},\) em \(D_{n+1}.\) Para isso, começamos fazendo</p>
\[
X_d^{(n+1)} = X_d^{(n)}, \qquad \forall d\in D_n.
\]
<p>Agora, para \(d \in D_{n+1} \setminus D_n,\) tomamos a média em relação aos valores adjacentes \(d \pm 1/2^n\) e somamos uma fração apropriada de \(Z_d\):</p>
\[
X_d^{(n+1)} = \frac{X_{d - 1/2^n}^{(n)} + X_{d + 1/2^n}^{(n)}}{2} + \frac{Z_d}{2^{(n + 1)/2}}.
\]
<p>Observe que, com \(n = 1,\) esta fórmula coincide com a fórmula acima dada explicitamente para \(\{X_d^{(2)}\}_{d\in D_2}.\)</p>
<p>A escolha da fração \(1/2^{(n+1)/2}\) no termo \(Z_d\) é para que esta fração tenha a variância adequada, como veremos a seguir.</p>

<img src="/notas_sde/assets/pages/c05/existencia_processo_wiener/code/output/sequenciaWn.svg" alt="">
<h3 id="processos_discretos_e_incrementos_são_gaussianos"><a href="#processos_discretos_e_incrementos_são_gaussianos" class="header-anchor">Processos discretos e incrementos são Gaussianos</a></h3>
<p>Observe que os processos são construídos como combinações lineares de variáveis normais independentes. Sendo assim, os processos \(\{X_d^{(n)}\}_{d\in D_n}\) são processos Gaussianos, i.e. a sua distribuição conjunta é uma normal multivariada &#40;note que cada \(D_n\) é finito, então esses processos são <em>vetores</em> aleatórios&#41;.</p>
<p>É importante ressaltar, no entanto, que cada \(\{X_d^{(n)}\}_{d\in D_n}\) não é formado por variáveis aleatórias independentes.</p>
<p>Da mesma forma, os incrementos são combinações lineares de normais independentes, portanto também são normais multivariadas. Em princípio, também não seriam independentes. Mas veremos a seguir que os incrementos têm uma estrutura particular, de tal forma que são, sim, independentes.</p>
<h3 id="independência_e_distribuição_dos_incrementos"><a href="#independência_e_distribuição_dos_incrementos" class="header-anchor">Independência e distribuição dos incrementos</a></h3>
<p>Observe que cada \(X_d^{(n)}\) só depende das variáveis \(\{Z_d\}_{d\in D_n},\) que são independentes de \(\{Z_d\}_{d \in D \setminus D_n}.\) Portanto, os processos \((X_d^{(n)})_{d\in D_n}\) e \(\{Z_d\}_{d \in D \setminus D_n}\) são independentes.</p>
<p>Agora, vamos ver que os incrementos de cada processo \(\{X_d^{(n)}\}_{d\in D_n}\) são independentes. Para \(n = 1,\) isso é vácuo, já que só há um incremento, \(X_1^{(1)} - X_0^{(1)} = Z_1.\) Para \(n = 2,\) temos apenas dois incrementos,</p>
\[
\Delta_{1/2}^{(2)} = X_1^{(2)} - X_{1/2}^{(2)} = X_1^{(1)} - \frac{X_0^{(1)} + X_1^{(1)}}{2} - \frac{Z_{1/2}}{2} = \frac{X_1^{(1)} - X_0^{(1)}}{2} - \frac{Z_{1/2}}{2} = \frac{Z_1}{2} - \frac{Z_{1/2}}{2}
\]
<p>e</p>
\[
\Delta_0^{(2)} = X_{1/2}^{(2)} - X_0^{(2)} = \frac{X_0^{(1)} + X_1^{(1)}}{2} + \frac{Z_{1/2}}{2} - X_0^{(2)} = \frac{X_1^{(1)} - X_0^{(1)}}{2} + \frac{Z_{1/2}}{2} = \frac{Z_1}{2} + \frac{Z_{1/2}}{2}.
\]
<p>Aparentemente, esses incrementos poderiam não ser independentes, mas são. Como \(Z_1\) e \(Z_{1/2}\) são independentes e são normais identicamente distribuídas com distribuição \(\mathcal{N}(0,1),\) então \(Z_1/2\) e \(Z_{1/2}/2\) são independentes e são normais identicamente distribuídas com distribuição \(\mathcal{N}(0,1/4).\) Assim, a soma e a diferença de \(Z_1/2\) e \(Z_{1/2}/2,\) que são exatamente os incrementos, são, também, normais independentes e identicamente distribuídas, com distribuição \(\mathcal{N}(0, 1/2).\) Além disso, também são independentes de \(\{Z_d\}_{d \in D \setminus D_2}.\)</p>
<p>Agora, vamos assumir, em um argumento de indução, que os incrementos de \(\{X_d^{(n)}\}_{d \in D_n}\) são independentes e identicamente distribuídos, com distribuição</p>
\[
X_{d + 1/2^{n-1}}^{(n)} - X_d^{(n)} \sim \mathcal{N}\left(0, \frac{1}{2^{n-1}}\right).
\]
<p>Além disso, assumimos que são independentes de \(\{Z_d\}_{d\in D \setminus D_n}.\)</p>
<p>Vamos mostrar que o mesmo vale para \(\{X_d^{(n+1)}\}_{d\in D_{n+1}},\) com incrementos consecutivos sendo normais independentes com média zero, variância \(1/2^n\) e independentes de \(\{Z_d\}_{d\in D \setminus D_{n+1}}.\)</p>
<p>Considere \(d \in D_{n+1}\setminus D_n,\) lembremos que</p>
\[
X_d^{(n+1)} = \frac{X_{d - 1/2^n}^{(n)} + X_{d + 1/2^n}^{(n)}}{2} + \frac{Z_d}{2^{(n+1)/2}}.
\]
<p>Os dois incrementos consecutivos com ponto comum \(d\) são</p>
\[
X_d^{(n+1)} - X_{d - 1/2^n}^{(n+1)} = \frac{X_{d + 1/2^n}^{(n)} - X_{d - 1/2^n}^{(n)}}{2} + \frac{Z_d}{2^{(n+1)/2}}
\]
<p>e</p>
\[
X_{d + 1/2^n}^{(n+1)} - X_d^{(n+1)} = \frac{X_{d + 1/2^n}^{(n)} - X_{d - 1/2^n}^{(n)}}{2} - \frac{Z_d}{2^{(n+1)/2}}.
\]
<p>Observe que \(X_{d + 1/2^n}^{(n)} - X_{d - 1/2^n}^{(n)}\) é um passo consecutivo do processo \(\{X_d^{(n)}\}_{d\in D_n}.\) Assim, usando a hipótese de indução, temos que \(X_{d + 1/2^n}^{(n)} - X_{d - 1/2^n}^{(n)}\) e \(Z_d\) são independentes e que \(X_{d + 1/2^n}^{(n)} - X_{d - 1/2^n}^{(n)} \sim \mathcal{N}(0, 1/2^{n-1}).\) Assim, temos</p>
\[
\frac{X_{d + 1/2^n}^{(n)} - X_{d - 1/2^n}^{(n)}}{2} \quad \text{e} \quad \frac{Z_d}{2^{(n+1)/2}} \sim \mathcal{N}\left(0, \frac{1}{2^{n+1}}\right).
\]
<p>Portanto, as suas somas e diferenças, que são exatamente os dois passos consecutivos, também são independentes e identicamente distribuídos, com distribuição \(\mathcal{N}(0, 1/2^{n+1} + 1/2^{n+1}) = \mathcal{N}(0, 1/2^n).\)</p>
<p>Isso mostra que dois passos consecutivos de \(\{X_d^{(n+1)}\}_{d\in D_{n+1}},\) com ponto em comum \(d\) em \(d \in D_{n+1}\setminus D_n,\) são independentes e a distribuição dada como na indução. Agora, se \(d \in D_n\setminus,\) então \(d \pm 1/2^n \in D_{n+1} \setminus D_n.\) Nesse caso, os passos consecutivos envolvem um estêncil de cinco pontos diádicos:</p>
\[
X_d^{(n+1)} - X_{d - 1/2^n}^{(n+1)} = X_d^{(n)} - \frac{X_{d}^{(n)} + X_{d - 1/2^{n-1}}^{(n)}}{2} - \frac{Z_{d-1/2^n}}{2^{(n+1)/2}} = \frac{X_{d}^{(n)} - X_{d - 1/2^{n-1}}^{(n)}}{2} - \frac{Z_{d-1/2^n}}{2^{(n+1)/2}}
\]
<p>e</p>
\[
X_{d + 1/2^n}^{(n+1)} - X_d^{(n+1)} = \frac{X_{d + 1/2^{n-1}}^{(n)} - X_d^{(n)}}{2} + \frac{Z_{d+1/2^n}}{2^{(n+1)/2}}.
\]
<p>Observe que os dois incrementos no lado direito das duas expressões acima são incrementos consecutivos do processo \(\{X_d^{(n)}\}_{d\in D_n}\) e que os termos restantes são variáveis distintas de \(\{Z_d\}_{d\in D\setminus D_n}.\) Pela hipótese de indução, todas essas variáveis são mutuamente independentes. Portanto, os dois incrementos acima de \(\{X_d^{(n+1)}\}_{d\in D_{n+1}}\) também são independentes entre si. Além disso, como esses termos do lado direito tem distribuição normal \(\mathcal{N}(0, 1/2^{n+1}),\) então os incrementos tem distribuição normal \(\mathcal{N}(0, 1/2^n).\)</p>
<p>Provamos que quaisquer dois incrementos consecutivos de \(\{X_d^{(n+1)}\}_{d\in D_{n+1}}\) são independentes dois a dois. Como a distribuição conjunta é normal, segue, da independência dois a dois, que todos os incrementos consecutivos são mutuamente independentes.</p>
<p>Disso segue, também, que incrementos disjuntos a &quot;passos largos&quot; \(X_{d_2}^{n+1} - X_{d_1}^{n+1},\) \(X_{d_3}^{n+1} - X_{d_2}^{n+1},\) ..., com \(d_1 < d_2 < d_3 < \ldots < d_n\) em \(D_{n+1},\) também são independentes, pois cada incremento desses é combinação linear de passos &quot;curtos&quot; independentes distintos.</p>
<p>Finalmente, como eles só envolvem \(\{Z_d\}_{d\in D \setminus D_{n+1}},\) então os incrementos de \(\{X_d^{(n+1)}\}_{d\in D_{n+1}}\) e os processos restantes \(\{Z_d\}_{d\in D \setminus D_{n+1}}\) também são mutuamente independentes.</p>
<h3 id="comentário_sobre_a_definição_da_distribuição_no_ponto_médio"><a href="#comentário_sobre_a_definição_da_distribuição_no_ponto_médio" class="header-anchor">Comentário sobre a definição da distribuição no ponto médio</a></h3>
<p>A definição de \(X_d^{(n+1)}\) em \(d\in D_{n+1}\setminus D_n\) como a média entre \(X_{d - 1/2^n}^{(n)}\) e \(X_{d + 1/2^n}^{(n)}\) mais uma normal independente está ligada a distribuição <em>ponte</em> do processo de Wiener em um instante \(t'\) dados os valores em outros dois pontos em torno de \(t'.\) Mais precisamente, tomemos, por exemplo, \(t'= 1/2,\) como ponto médio entre \(0\) e \(1.\) Então</p>
\[
    \begin{cases}
        W_1 - W_{1/2} = S_0 \sim \mathcal{N}(0, 1/2), \\
        W_{1/2} - W_0 = S_1 \sim \mathcal{N}(0, 1/2),
    \end{cases}
\]
<p>com os passos \(S_0\) e \(S_1\) independentes. Subtraindo, obtemos</p>
\[
    W_1 + W_0 - 2W_{1/2} = S_1 - S_0.
\]
<p>Com isso,</p>
\[
    W_{1/2} = \frac{W_0 + W_1}{2} + \frac{S^-}{2}, \qquad S^- = S_1 - S_0 \sim \mathcal{N}(0, 1).
\]
<p>Além disso,</p>
\[
    W_0 + W_1 = W_0 + W_0 + W_1 - W_0 = 2W_0 + S_1 + S_0 = 2W_0 + S^+,
\]
<p>onde</p>
\[
    S^+ = S_1 + S_0 \sim \mathcal{N}(0, 1),
\]
<p>com \(S^+\) e \(S^-\) independentes, de modo que</p>
\[
    \frac{W_0 + W_1}{2} \quad \textrm{e} \quad \frac{S^-}{2}
\]
<p>são independentes.</p>
<p>Observe que, nesse exemplo específico, \(W_0 = 0,\) mas em outros pontos, de forma mais geral, teríamos um \(W_{t_0}\) não necessariamente nulo mas, de qualquer forma, independente dos passos futuros e dos \(S_1, S_2, S^+, S^-\) correspondentes.</p>
<h2 id="interpolação"><a href="#interpolação" class="header-anchor">Interpolação</a></h2>
<p>Definimos \(\{W_t^{(n)}\}_{0\leq t \leq 1}\) como sendo a interpolação linear por partes do processo &#40;digo, vetor aleatório&#41; \(\{X_d^{(n)}\}_{d\in D_n}.\) Tal interpolação pode ser representada por</p>
\[
    W_t^{(n)} = \sum_{d\in D_n} \varphi_{n,d}(t) X_d^{(n)},
\]
<p>onde cada \(\varphi_{n,d}=\varphi_{n,d}(t)\) é a função &quot;tenda&quot;</p>
\[
    \varphi_{n,d}(t) = \max\{0, 1 - 2^{n-1}|t - d|\} = \begin{cases}
      0, & |t - d| \geq 1/2^{n-1}, \\
      1 - 2^{n-1}(d - t), & d - 1/2^{n-1} \leq t \leq d, \\
      1 - 2^{n-1}(t - d), & d \leq t \leq d + 1/2^{n-1},
    \end{cases},
\]
<p>que se anula para \(|t - d| \geq 1/2^{n-1},\) vale \(1\) em \(t = d\) e é linear nos intervalos da malha diádica \(D_n.\)</p>
<p>Mas essa representação não nos será tão útil. Vamos usar uma outra representação, diretamente em termos de \(\{Z_d\}_{d\in D},\) que pode ser obtida por indução. Como todos os \(X_d^{(n)}\) são definidos em termos das variáveis \(Z_d,\) \(d\in D_n,\) então, substituindo recursivamente o processo discreto chegamos a</p>
\[
    W_t^{(n)} = \sum_{d\in D_n} s_d(t) Z_d,
\]
<p>para funções de interpolação apropriadas \(s_d=s_d(t).\) A questão é como obter essas funções de maneira mais explícita. Vejamos o primeiro processo \(\{W_t^{(1)}\}_{0\leq t \leq 1}.\) Este é um interpolação linear entre</p>
\[
    X_0^{(1)} = Z_0 = 0, \quad X_1^{(1)} = Z_1.
\]
<p>A interpolação linear entre esses pontos toma a forma</p>
\[
    W_t^{(1)} = (1 - t)Z_0 + tZ_1, \quad 0 \leq t \leq 1.
\]
<p>De outra maneira, podemos escrever</p>
\[
    W_t^{(1)} = s_0(t)Z_0 + s_1(t)Z_1,
\]
<p>com as funções estendidas à toda a reta e escrita em termos das funções-tenda anteriores,</p>
\[
    s_0(t) = \varphi_{1,0}(t) = \max\{0, 1 - |t|\}, \quad s_1(t) = \varphi_{1,1}(t) = \max\{0, 1 - |t - 1|\}.
\]
<p>Podemos juntar as duas expressões na fórmula</p>
\[
    s_d(t) = \max\{0, 1 - |t - d|\}, \quad d = 0, 1.
\]
<p>Para \(\{W_t^{(2)}\}_{0\leq t \leq 1},\) observamos que \(\{X_d^{(2)}\}_{d\in D_2}\) é obtido a partir de \(\{X_d^{(1)}\}_{d\in D_1}\) acresentando \(Z_{1/2}/2\) à média entre os valores em \(t=0\) e \(t=1,\) de modo que</p>
\[
    W_t^{(2)} = W_t^{(1)} + s_{1/2}(t)Z_{1/2}.
\]
<p>Isso, de fato, vale em geral e segue direto da própria expansão que queremos explicitar,</p>
\[
    W_t^{(n+1)} = \sum_{d\in D_{n+1}} s_d(t) Z_d = \sum_{d\in D_{n}} s_d(t) Z_d + \sum_{d\in D_{n+1}\setminus D_{n}} s_d(t) Z_d = W_t^{(n)} + \sum_{d\in D_{n+1}\setminus D_{n}} s_d(t) Z_d.
\]
<p>O termo que estamos somando,</p>
\[
    s_{1/2}(t)Z_{1/2},
\]
<p>é uma interpolação entre \(Z_{1/2}/2\) no ponto médio \(t=1/2\) e o valor nulo nos extremos \(t=0\) e \(t=1.\) Assim, \(s_{1/2}(t)\) é um interpolação linear por partes entre \(s_{1/2}(0) = s_{1/2}(1) = 0\) e \(s_{1/2}(1/2) = 1/2.\) Tal função pode ser escrita na forma</p>
\[
    s_{1/2}(t) = \frac{1}{2}\max\{0, 1 - 2|t - 1/2|\} = \min\{0, t, 1 - t\}.
\]
<p>Assim,</p>
\[
    W_t^{(2)} = s_0(t)Z_0 + s_1(t)Z_1 + s_{1/2}Z_{1/2},
\]
<p>com as funções \(s_0, s_1, s_{1/2}\) definidas por</p>
\[
    s_d(t) = \max\{0, 1 - |t - d|\}, \; d = 0, 1, \qquad s_{1/2}(t) = \frac{1}{2}\max\{0, 1 - 2|t - 1/2|\}.
\]
<p>Agora, assumindo, em um argumento de indução, que tenhamos, para um dado \(n,\) as fórmulas para \(s_d(t),\) \(d\in D_n,\) e a expansão</p>
\[
    W_t^{(n)} = \sum_{d\in D_n} s_d(t) Z_d,
\]
<p>vamos usar que</p>
\[
    W_t^{(n+1)} = W_t^{(n)} + \sum_{d\in D_{n+1}\setminus D_{n}} s_d(t) Z_d
\]
<p>para encontrar as funções no nível \(D_{n+1}\setminus D_{n}.\) Em tal nível, cada \(s_d(t)\) em \(d\in D_{n+1}\setminus D_{n}\) é um interpolação que se anula em todos os subintervalos da partição diádica exceto no intervalo \((d - 1/2^n, d + 1/2^n),\) no qual ele tem uma forma de tenda, se anulando nos extremos desse intervalo e valendo</p>
\[
    s_d(d) = \frac{1}{2^{(n+1)/2}},
\]
<p>no centro do subintervalo. Uma tal função linear por partes pode ser escrita como um múltiplo \(1/2^{(n+1)/2}\) de uma função &quot;tenda&quot; que vale \(1\) no centro, portanto com inclinações \(2^n\) e \(-2^n,\) nos subintervalos \((d - 1/2^n, d)\) e \((d, d + 1/2^n),\) respectivamente. Isso pode ser escrito na forma sucinta</p>
\[
    s_d(t) = \frac{1}{2^{(n+1)/2}}\max\{0, 1 - 2^n|t - d|\}, \quad d\in D_{n+1}\setminus D_n.
\]
<p>Observe que essa fórmula inclui as fórmulas para \(s_0(t),\) \(s_1(t)\) e \(s_{1/2}(t)\) explicitadas acima. Dessa maneira, obtemos a expansão desejada</p>
\[
    W_t^{(n)} = \sum_{d\in D_n} s_d(t) Z_d,
\]
<p>com</p>
\[
    s_d(t) = \frac{1}{2^{(n+1)/2}}\max\{0, 1 - 2^n|t - d|\}, \quad d\in D_{n+1}\setminus D_n,
\]
<p>para \(n\in \mathbb{N}\) arbitrário.</p>

<img src="/notas_sde/assets/pages/c05/existencia_processo_wiener/code/output/faberschauder.svg" alt="">
<p>A razão de explicitarmos essas funções é que precisaremos fazer estimativas para mostrar a convergência dessas aproximações. Com isso, precisamos de estimativas para essas funções de interpolação.</p>
<p>Com isso em mente, observe que cada \(s_d(t)\) é não negativa e com ponto máximo em \(t=d.\) Para \(d\in D_{n+1}\setminus D_n,\) o valor máximo, obtido em \(t=d,\) é </p>
\[
  s_d(d) = \frac{1}{2^{(n+1)/2}}.
\]
<p>Assim,</p>
\[
    0 \leq s_d(t) \leq \frac{1}{2^{(n+1)/2}}, \qquad t\in\mathbb{R}.
\]
<p>Além disso, as funções de interpolação em um mesmo nível \(D_{n+1}\setminus D_n\) têm suportes que não se sobrepõe &#40;não encaixantes ou <em>non overlapping</em>&#41;. Com isso, podemos somar as funções de interpolação em cada nível sem aumentar essa cota, i.e.</p>
\[
    0 \leq \sum_{d\in D_{n+1}\setminus D_n} s_d(t) \leq \frac{1}{2^{(n+1)/2}}, \quad \forall n\in\mathbb{N}.
\]
<p>Cada \(s_d\) pode ser visto como uma primitiva de uma base de wavelets, a <strong>base de Haar</strong>, formada por funções constantes por partes,</p>
\[
\psi_1(t) = 1, \quad 
\psi_d(t) = \frac{\mathrm{d}s_d}{\mathrm{d}t} = \begin{cases}
  0, & t \leq d - \frac{1}{2^n}, \\
  2^{(n-1)/2}, & d - \frac{1}{2^n} \leq t \leq d, \\
  - 2^{(n-1)/2}, & d \leq t \leq d + \frac{1}{2^n}, \\
  0, & t \geq d + \frac{1}{2^n}
\end{cases} \qquad d \in D_{n+1} \setminus D_n, \; n\in \mathbb{N}.
\]
<p>Observe, também, que</p>
\[
\int_0^1 \psi_d(t)^2 \;\mathrm{d}t = 2 \times (2^{(n-1)/2})^2 \frac{1}{2^n} = 1.
\]
<h3 id="representação_em_série"><a href="#representação_em_série" class="header-anchor">Representação em série</a></h3>
<p>Obtivemos, acima, então, que</p>
\[
W_t^{(n)} = \sum_{d\in D_n} s_d(t) Z_d, \qquad 0 \leq t \leq 1
\]
<p>é uma representação para a interpolação linear do processo discreto \(\{X_d^{(n)}\}_{d\in D_n},\) i.e. \(W_d^{(n)} = X_d^{(n)},\) para todo \(d\in D_n\) e que \(W_t^{(n)}\) é linear em cada intervalo \([d, d + 1/2^n]\) com \(d, d + 1/2^n\in D_n.\)</p>
<h2 id="limite"><a href="#limite" class="header-anchor">Limite</a></h2>
<p>A ideia, agora, é passar ao limite e definir o processo de Wiener \(\{W_t\}_{t\in [0, 1]}\) através da série</p>
\[
W_t = \sum_{d\in D} s_d(t) Z_d, \qquad 0 \leq t \leq 1.
\]
<p>Para isso, precisamos mostrar a convergência dessa série. Vamos mostrar que, com probabilidade \(1,\) essa convergência se dá uniformemente em \(0 \leq t \leq 1.\) Podemos escrever isso como</p>
\[
\mathbb{P}\left( \lim_{m, n\rightarrow 0} \max_{0\leq t\leq 1} |W_t^{(m)} - W_t^{(n)}| = 0\right) = 1.
\]
<p>Ou, então, que</p>
\[
\lim_{m, n\rightarrow 0} \max_{0\leq t\leq 1} |W_t^{(m)} - W_t^{(n)}| = 0 \quad \textrm{quase sempre,}
\]
<p>ou, mais explicitamente,</p>
\[
\lim_{m, n\rightarrow 0} \max_{0\leq t\leq 1} |W_t^{(m)}(\omega) - W_t^{(n)}(\omega)| = 0 \quad \textrm{para quase todo } \omega \in \mathbb{R}^D.
\]
<h3 id="plano_para_a_demonstração"><a href="#plano_para_a_demonstração" class="header-anchor">Plano para a demonstração</a></h3>
<p>A ideia é obter uma estimativa para a sequência de Cauchy em termos de um processo discreto \((A_n)_{n\in\mathbb{N}}\) com valores não-negativos e com \(A_n \rightarrow 0\) quase sempre, definido no mesmo espaço amostral \(\Omega,\) i.e.</p>
\[
\max_{0\leq t\leq 1} |W_t^{(m)}(\omega) - W_t^{(n)}(\omega)| \leq A_n(\omega), \quad \forall m \geq n,
\]
<p>com</p>
\[
A_n \rightarrow 0,
\]
<p>quase certamente.</p>
<h3 id="processo_a_n"><a href="#processo_a_n" class="header-anchor">Processo \(A_n\)</a></h3>
<p>Para obter a estimativa acima, usamos a representacão em série de \(\{W_t^{(n)}\}_n\) para estimar, para \(m\geq n,\)</p>
\[
|W_t^{(m)} - W_t^{(n)}| = \left|\sum_{d\in D_m\setminus D_n} s_d(t) Z_d \right| \leq \sum_{k = n}^\infty \sum_{d\in D_{k+1}\setminus D_k} \left| s_d(t) Z_d \right| \leq \sum_{k = n}^\infty \left(\max_{d\in D_{k+1}\setminus D_k} |Z_d|\sum_{d\in D_{k+1}\setminus D_k} s_d(t)\right).
\]
<p>para todo \(0\leq t \leq 1.\) Como visto acima, em cada nível \(D_{k+1}\setminus D_k,\) as funções \(s_d=s_d(t)\) têm suportes não encaixantes e o somatório é limitado pelo máximo dessas funções, que é exatamente \(1/2^{(k+1)/2},\) ou seja,</p>
\[
0 \leq \sum_{d\in D_{k+1}\setminus D_k} s_d(t) \leq \frac{1}{2^{(k+1)/2}}.
\]
<p>Portanto,</p>
\[
|W_t^{(m)} - W_t^{(n)}| = \left|\sum_{d\in D_m\setminus D_n} s_d(t) Z_d \right| \leq \sum_{k = n}^\infty \sum_{d\in D_{k+1}\setminus D_k} \left| s_d(t) Z_d \right| \leq \sum_{k = n}^\infty \frac{1}{2^{(k+1)/2}}\max_{d\in D_{k+1}\setminus D_k} |Z_d|.
\]
<p>O lado direito é independente de \(t\) e de \(m \geq n.\) Assim, podemos escrever</p>
\[
\max_{m\geq n} \sup_{0\leq t \leq 1} |W_t^{(m)} - W_t^{(n)}| \leq A_n,
\]
<p>onde</p>
\[
A_n = \sum_{k = n}^\infty \frac{1}{2^{(k+1)/2}}\max_{d\in D_{k+1}\setminus D_k} |Z_d|.
\]
<p>Para obter que \(A_n \rightarrow 0,\) basta mostrar que a série converge quase sempre.</p>
<h3 id="convergência_da_série"><a href="#convergência_da_série" class="header-anchor">Convergência da série</a></h3>
<p>Queremos mostrar, portanto, que</p>
\[
\sum_{k = 1}^\infty \frac{1}{2^{(k+1)/2}}\max_{d\in D_{k+1}\setminus D_k} |Z_d| < \infty
\]
<p>quase sempre. A ideia para isso é mostrar que podemos estimar, quase sempre,</p>
\[
|Z_d| \leq r_k, \quad \forall d\in D_{k+1}\setminus D_k, \;\forall k \geq N,
\]
<p>para algum \(N=N(\omega)\) e para uma série apropriada \(r_k.\) Se isso for possível, então, quase sempre, teremos</p>
\[
\sum_{k = 1}^\infty \frac{1}{2^{(k+1)/2}}\max_{d\in D_{k+1}\setminus D_k} |Z_d| \leq \sum_{k = 1}^\infty \frac{1}{2^{(k+1)/2}}r_k.
\]
<p>Assim, precisamos mostrar que existe uma sequência \(\{r_k\}_{k\in\mathbb{N}}\) de números reais tais que o somatório ao lado direito acima seja finito e que a estimativa</p>
\[
|Z_d| \leq r_k, \quad \forall d\in D_{k+1}\setminus D_k, \;\forall k \geq N,
\]
<p>valha quase sempre, para alguma variável aleatória \(N=N(\omega)\) com valores nos números naturais. Isso é equivalente a mostrar que</p>
\[
\left\{ \exists d \in D_{k+1}\setminus D_k, \; |Z_d| > r_k \textrm{ infinitas vezes} \right\}.
\]
<p>tem probabilidade nula. Ou seja, que</p>
\[
\mathbb{P}\left(\limsup_{k\rightarrow \infty} \left\{\exists d \in D_{k+1}\setminus D_k, \; |Z_d| > r_k\right\} \right) = 0.
\]
<p>Isso está no contexto do Lema de Borel-Cantelli, cuja condição é que</p>
\[
\sum_{k=1}^\infty \mathbb{P}\left(\exists d \in D_{k+1}\setminus D_k, \; |Z_d| > r_k \right) < \infty
\]
<p>Observe que </p>
\[
\sum_{k=1}^\infty \mathbb{P}\left(\exists d \in D_{k+1}\setminus D_k, \; |Z_d| > r_k \right) = \mathbb{P}\left(\bigcup_{d \in D_{k+1}\setminus D_k}\left\{|Z_d| > r_k\right\}\right) \leq \sum_{k=1}^\infty \sum_{d \in D_{k+1}\setminus D_k} \mathbb{P}\left( |Z_d| > r_k \right) < \sum_{k=1}^\infty 2^{k-1} \mathbb{P}\left( |Z_d| > r_k \right).
\]
<p>Portanto, precisamos achar uma sequência \(\{r_k\}_{k\in\mathbb{N}}\) de números positivos tais que</p>
\[
\sum_{k = 1}^\infty \frac{1}{2^{(k+1)/2}}r_k < \infty
\]
<p>e</p>
\[
\sum_{k=1}^\infty 2^{k-1} \mathbb{P}\left( |Z_d| > r_k \right) < \infty.
\]
<h3 id="estimativa_para_a_concentração_de_processos_iid_normais"><a href="#estimativa_para_a_concentração_de_processos_iid_normais" class="header-anchor">Estimativa para a concentração de processos i.i.d. normais</a></h3>
<p>Precisamos, assim, obter uma estimativa para as variáveis aleatórias \(Z_d\) do processo \(\{Z_d\}_{d\in D}.\) Como elas são independentes, a função de densidade de probabilidade das marginais desse processo é dada pela Gaussiana padrão. Assim, para cada \(d\in D\) e para \(r \geq 0\) arbitrário,</p>
\[
\mathbb{P}(|Z_d| \geq r) = \frac{1}{\sqrt{2\pi}}\int_{|s|\geq r} e^{-\frac{s^2}{2}} \;\mathrm{d}s \leq \frac{1}{\sqrt{2\pi}}e^{-\frac{r^2}{4}} \int_{|s| \geq r} e^{-\frac{s^2}{4}} \;\mathrm{d}s.
\]
<p>Limitando a integral e fazendo a mudança de variáveis \(s = \sqrt{2}\sigma,\) obtemos</p>
\[
\mathbb{P}(|Z_d| \geq r) \leq \frac{1}{\sqrt{2\pi}}e^{-\frac{r^2}{4}} \int_\mathbb{R} e^{-\frac{s^2}{4}} \;\mathrm{d}s = \frac{\sqrt{2}}{\sqrt{2\pi}}e^{-\frac{r^2}{4}}\int_\mathbb{R} e^{-\frac{\sigma^2}{2}} \;\mathrm{d}\sigma = \sqrt{2} e^{-\frac{r^2}{4}}.
\]
<p>Em particular,</p>
\[
\mathbb{P}(|Z_d| > r_k) \leq \sqrt{2} e^{-\frac{r_k^2}{4}},
\]
<p>para um \(r_k \geq 0\) qualquer.</p>
<h3 id="escolha_dos_r_k"><a href="#escolha_dos_r_k" class="header-anchor">Escolha dos \(r_k\)</a></h3>
<p>Assim, removendo o fator \(\sqrt{2}\) que é independente de \(k,\) precisamos encontrar \(\{r_k\}_{k\in\mathbb{N}}\) tais que</p>
\[
\sum_{k = 1}^\infty \frac{1}{2^{k/2}}r_k < \infty, \quad \textrm{e} \quad \sum_{k=1}^\infty 2^k e^{-\frac{r_k^2}{4}} < \infty.
\]
<p>Observe que \(r_k\) tem que crescer suficientemente rápido para que a exponencial ganhe da potência de dois, no segundo somatório, mas não pode crescer muito rápido, para não ganhar do denominador no primeiro somatório. Procurando um crescimento potencial \(r_k = k^\alpha,\) vemos que qualquer valor \(\alpha>1/2\) é suficiente, já que é subexponencial, perdendo pro decrescimento exponencial \(1/2^k,\) e \(r_k^2 \geq k^{2\alpha},\) de tal forma que \(e^{-r_k^2} \leq e^{-k^{2\alpha}},\) que ganha de \(2^k.\) Também podemos escolher \(\alpha=1/2\) desde que multipiquemos a sequência por um fator apropriado. Essa escolha nos dá a taxa de decrescimento dos coeficientes a mais rápida possível. Observe que, escolhendo \(r_k = 2\sqrt{k},\) temos</p>
\[
\sum_{k=1}^\infty 2^k e^{-\frac{r_k^2}{4}} \leq \sum_{k=1}^\infty 2^k e^{-k} \leq \sum_{k=1}^\infty e^{k\ln 2} e^{-k} = \sum_{k=1}^\infty e^{- (1 - \ln 2)k} < \infty,
\]
<p>já que \(\ln 2 < 1.\) Por outro lado,</p>
\[
\sum_{k = 1}^\infty \frac{1}{2^{k/2}}r_k \leq \sum_{k = 1}^\infty \frac{1}{2^{k/2}}2\sqrt{k} < \infty.
\]
<h3 id="concluindo_a_demonstração_de_convergência"><a href="#concluindo_a_demonstração_de_convergência" class="header-anchor">Concluindo a demonstração de convergência</a></h3>
<p>Recapitulando. Provamos que</p>
\[
\max_{m \geq n \geq N}\max_{0\leq t\leq 1} |W_t^{(m)} - W_t^{(n)}| \leq A_n \rightarrow 0
\]
<p>quase sempre, de modo que</p>
\[
\lim_{m, n \rightarrow \infty} \max_{0\leq t\leq 1} |W_t^{(m)} - W_t^{(n)}| = 0
\]
<p>quase sempre. Isso demonstra que a série é uniformenente convergente para quase todo \(\omega\in\mathbb{R}^D.\) Portanto, podemos definir \(\{W_t\}_{t\in [0, 1]}\) por</p>
\[
W_t = \sum_{d\in D} s_d(t) Z_d, \qquad 0 \leq t \leq 1.
\]
<p>Além disso, para quase todo \(\omega,\) o caminho amostral \(W_t(\omega)\) é o limite uniforme dos caminhos contínuos \(W_t^{(n)}(\omega),\) sendo, também, contínuo.</p>
<h3 id="mais_explicitamente"><a href="#mais_explicitamente" class="header-anchor">Mais explicitamente</a></h3>
<p>Podemos ser um pouco mais explícitos e considerar o conjunto &quot;bom&quot;</p>
\[
    G = \bigcup_{n\in\mathbb{N}}\bigcap_{m \geq n} \bigcap_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| \leq r_k\}.
\]
<p>Nesse conjunto, i.e. para todo \(\omega\in G,\) temos que existe \(N=N(\omega)\) tal que</p>
\[
    \bigcap_{m \geq N(\omega)} \bigcap_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| \leq r_k\}.
\]
<p>Como esses conjuntos são não crescentes em \(n,\) temos, de fato, que</p>
\[
    \bigcap_{m \geq n} \bigcap_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| \leq r_k\}, \qquad \forall n \geq N(\omega).
\]
<p>Assim,</p>
\[
    \max_{m \geq n}\max_{0\leq t\leq 1} |W_t^{(m)}(\omega) - W_t^{(N(\omega))}(\omega)| \leq A_{n}(\omega) = \sum_{k = n}^\infty \frac{1}{2^{(k+1)/2}}\max_{d\in D_{k+1}\setminus D_k} |Z_d(\omega)| \leq \sum_{k = n}^\infty \frac{1}{2^{(k+1)/2}} r_k,
\]
<p>Como a série é convergente para \(r_k = 2\sqrt{k},\) temos que o rabo da série decai para zero, i.e. </p>
\[
    \max_{m \geq n}\max_{0\leq t\leq 1} |W_t^{(m)}(\omega) - W_t^{(N(\omega))}(\omega)| \leq \sum_{k = n}^\infty \frac{1}{2^{(k+1)/2}} r_k \rightarrow 0, \quad n\rightarrow \infty.
\]
<p>Ou seja,</p>
\[
    \lim_{m, n\rightarrow 0} \max_{0\leq t\leq 1} |W_t^{(m)}(\omega) - W_t^{(n)}(\omega)| = 0, \quad \forall \omega \in G.
\]
<p>Falta mostrar que \(G\) tem probabilidade total, \(\mathbb{P}(G) = 1,\) ou seja, \(\mathbb{P}(\Omega \setminus G) = 0.\) Para tal, observe que</p>
\[
    \Omega \setminus G = \bigcap_{n\in\mathbb{N}}\bigcup_{m \geq n} \bigcup_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| > r_k\} = \limsup_{k\rightarrow \infty} \left(\bigcup_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| > r_k\}\right).
\]
<p>Assim, estamos no contexto do Lema de Borel-Cantelli. Basta provar que</p>
\[
    \sum_{k\in \mathbb{N}} \mathbb{P}\left( \bigcup_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| > r_k\} \right) < \infty
\]
<p>para deduzir que</p>
\[
    \mathbb{P}\left(\Omega \setminus G\right) = \mathbb{P}\left(\limsup_{k\rightarrow \infty} \left(\bigcup_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| > r_k\}\right)\right) = 0.
\]
<p>Para ver que o somatório é finita, observamos que</p>
\[
    \begin{align*}
        \sum_{k\in \mathbb{N}} \mathbb{P}\left( \bigcup_{d\in D_{k+1}\setminus D_k} \{\omega; \;|Z_d(\omega)| > r_k\} \right) & \leq \sum_{k\in \mathbb{N}} \sum_{d\in D_{k+1}\setminus D_k} \mathbb{P}\left(\{\omega; \;|Z_d(\omega)| > r_k\} \right) \\
        & \leq \sum_{k\in \mathbb{N}} \sum_{d\in D_{k+1}\setminus D_k} \sqrt{2}e^{-r_k^2/4} \\
        & \leq \sqrt{2}\sum_{k\in \mathbb{N}} 2^k e^{-r_k^2/4} \\
        & = \sqrt{2}\sum_{k\in \mathbb{N}} e^{k\ln(2)} e^{-k} \\
        & = \sqrt{2}\sum_{k\in\mathbb{N}} e^{-k(1 - \ln(2))} \\
        & < \infty,
    \end{align*}
\]
<p>dada a escolha \(r_k = 2\sqrt{k}.\)</p>
<p>Assim, mostramos que, com probabilidade \(1,\) a sequência converge uniformemente.</p>
<h2 id="processo_de_wiener_no_intervalo_unitário"><a href="#processo_de_wiener_no_intervalo_unitário" class="header-anchor">Processo de Wiener no intervalo unitário</a></h2>
<p>Resta mostrar que \(\{W_t\}_{t\in [0, 1]}\) tem todas as propriedades desejadas para que seja um processo de Wiener no intervalo \([0, 1].\) Para mostrarmos isso, vamos explorar a convergência obtida acima, que implica em convergência em distribuição, para passar ao limite as propriedades já estabelecidas para os processos discretos \(\{X_d^{(n)}\}_{d\in D_n},\) usando, também, que \(D\) é denso em \(I=[0,1].\)</p>
<h3 id="processo_inicial"><a href="#processo_inicial" class="header-anchor">Processo inicial</a></h3>
<p>Como \(s_d(0) = 0,\) para todo \(d\in D,\) segue imediatamente que</p>
\[
W_0 = \sum_{d\in D} s_d(0)Z_d = 0
\]
<h3 id="continuidade_dos_caminhos_amostrais"><a href="#continuidade_dos_caminhos_amostrais" class="header-anchor">Continuidade dos caminhos amostrais</a></h3>
<p>Construímos \(\{W_t^{(n)}\}_{t\in [0,1]}\) de tal forma que, para todo \(\omega\in \Omega,\) o caminho amostral \(t \mapsto W_t^{(n)}(\omega)\) é contínuo. Obtivemos, ainda, que cada caminho amostral \(t \mapsto W_t(\omega)\) é limite uniforme de \(t \mapsto W_t^{(n)}(\omega).\) Portanto, para todo \(\omega\in\Omega,\) o caminho amostral \(t \mapsto W_t(\omega)\) também contínuo. Em particular,</p>
\[
\mathbb{P}(\{\omega; \;t \mapsto W_t(\omega) \textrm{ é contínuo}\}) = 1.
\]
<p>As outras hipóteses da definição de um processo de Wiener, em particular as hipóteses do processo ser Gaussiano e dos incrementos serem normais com média zero e variância igual ao tamanho do passo temporal, não garantem que os caminhos sejam, quase certamente, contínuos, mas segue do <em>Teorema de Continuidade de Kolmogorov</em> que uma <em>modificação</em> quase sempre do processo tem caminhos que são Hölder contínuos com expoente arbitrariamente próximo de \(1/2.\) Portanto, é possível obter um processo de Wiener &#40;com a hipótese de continuidade quase certamente&#41; modificando um processo Gaussiano que satisfaça as outras hipóteses. A demonstração acima nos dá isso mais diretamente. </p>
<h3 id="independência_dos_incrementos"><a href="#independência_dos_incrementos" class="header-anchor">Independência dos incrementos</a></h3>
<p>Sejam \(0 \leq t_0 < t_1 < \ldots < t_n \leq 1,\) onde \(n\in \mathbb{N},\) \(n \geq 2.\) Dados eventos \(E_1, \ldots, E_n\in \mathbb{A},\) vamos considerar a probabilidade conjunta dos incrementos \(W_{t_j} - W_{t_{j-1}},\) \(j = 1, \ldots, n.\)</p>
\[
\mathbb{P}(W_{t_1} - W_{t_0} \in E_1, \ldots, W_{t_n} - W_{t_{n-1}} \in E_n).
\]
<p>Considere sequências \(\{t_j^k\}_{k\in \mathbb{N}}\) tais que \(t_j^k\in D,\) \(0 \leq t_0^k < t_1^k < \ldots < t_n^k \leq 1\) e \(t_j^k \rightarrow t_j,\) quando \(k \rightarrow \infty,\) para qualquer \(j = 0, \ldots, n.\)</p>
<p>Como os caminhos amostrais são contínuos, temos que \(W_{t_j^k}\) converge quase-sempre para \(W_{t_j},\) quando \(k \rightarrow \infty.\) Como cada incremento é Gaussiano e a função de distribuição de probabilidades de uma Gaussiana é contínua, seque que</p>
\[
\mathbb{P}(W_{t_j^k} - W_{t_{j-1}^k} \in E_1) \rightarrow \mathbb{P}(W_{t_j} - W_{t_{j-1}} \in E_1), \quad k \rightarrow \infty.
\]
<p>Da mesma forma, o conjunto de incrementos é uma Gaussiana multivariada e a função de distribuição de probabilidades de uma Gaussiana multivariada também é contínua, de modo que</p>
\[
\mathbb{P}(W_{t_1^k} - W_{t_0^k} \in E_1, \ldots, W_{t_n^k} - W_{t_{n-1}^k} \in E_n) \rightarrow \mathbb{P}(W_{t_1} - W_{t_0} \in E_1, \ldots, W_{t_n} - W_{t_{n-1}} \in E_n), \quad k \rightarrow \infty.
\]
<p>Já vimos que, em pontos diádicos, \(W_{t_j^k} = W_{t_j^k}^{n_k} = X_{t_j^k}^{n_k},\) para algum \(n_k\) tal que \(t_j^k\in D_{n_k},\) para todo \(j = 0, \ldots, n\) e para todo \(k\in \mathbb{N}.\) Já vimos, também, que os incrementos de \(\{X_d^{(n)}\}_{d\in D_n}\) são independentes. Portanto,</p>
\[
\mathbb{P}(W_{t_1^k} - W_{t_0^k} \in E_1, \ldots, W_{t_n^k} - W_{t_{n-1}^k} \in E_n) = \mathbb{P}(W_{t_1^k} - W_{t_0^k} \in E_1) \times \cdots \times \mathbb{P}(W_{t_n^k} - W_{t_{n-1}^k} \in E_n).
\]
<p>Passando ao limite \(k \rightarrow \infty\) dos dois lados da igualdade acima, obtemos</p>
\[
\mathbb{P}(W_{t_1} - W_{t_0} \in E_1, \ldots, W_{t_n} - W_{t_{n-1}} \in E_n) = \mathbb{P}(W_{t_1} - W_{t_0} \in E_1) \times \cdots \times \mathbb{P}(W_{t_n} - W_{t_{n-1}} \in E_n),
\]
<p>mostrando a independência dos incrementos.</p>
<h3 id="distribuição_dos_incrementos"><a href="#distribuição_dos_incrementos" class="header-anchor">Distribuição dos incrementos</a></h3>
<p>Sejam \(t\) e \(\tau\) tais que \(0\leq t < t + \tau \leq 1.\) Considere sequências \(\{t^k\}_{k\in \mathbb{N}},\) \(\{\tau_k\}_{k\in \mathbb{N}}\) tais que \(t^k \rightarrow t,\) \(\tau^k \rightarrow \tau,\) \(0 \leq t^k < t^k + \tau^k \leq 1\) e \(t^k, t^k + \tau^k \in D.\) Para cada \(k,\) temos, de fato, \(t^k, t^k + \tau^k\in D_{n_k},\) para \(n_k\in \mathbb{N}\) suficientemente grande.</p>
<p>Conforme argumentado acima, temos</p>
\[
\mathbb{P}(W_{t^k + \tau^k} - W_{t^k} \leq x) \rightarrow \mathbb{P}(W_{t + \tau} - W_t \leq x), \quad k \rightarrow \infty,
\]
<p>para todo \(x \in \mathbb{R}.\) Por outro lado, sabemos que \(W_{t^k + \tau^k} - W_{t^k} = X_{t^k + \tau^k}^{n_k} - X_{t^k}^{n_k} \sim \mathcal{N}(0, \tau^k),\) de forma que</p>
\[
\mathbb{P}(W_{t^k + \tau^k} - W_{t^k} \leq x) = F_{\tau_k}(x),
\]
<p>onde \(F_{\sigma^2}(\cdot)\) denota a função de distribuição acumulada da normal \(\mathcal{N}(0, \sigma^2),\) \(\sigma > 0.\) Passando ao limite em \(k\rightarrow \infty,\) obtemos</p>
\[
\mathbb{P}(W_{t + \tau} - W_{t} \leq x) = F_{\tau}(x).
\]
<p>Portanto,</p>
\[
W_{t + \tau} - W_{t} \sim \mathcal{N}(0, \tau).
\]
<p>Isso completa a demonstração de que \(\{W_t\}_{t\in [0, 1]}\) é um processo de Wiener em \([0, 1].\)</p>
<h2 id="extensão_para_a_semireta"><a href="#extensão_para_a_semireta" class="header-anchor">Extensão para a semireta</a></h2>
<p>Construímos um processo \(\{W_t\}_{t\in [0, 1]}\) com todas as propriedades de um processo de Wiener, exceto que só está definido no intervalo \([0, 1].\) Podemos construir um processo de Wiener em \([0, \infty)\) simplesmente transladando e concatenando processos em \([0, 1].\)</p>
<p>Sejam, então, \(\{W_t^k\}_{t \in [0, 1]},\) \(k\in \mathbb{N},\) processos independentes com as propriedades de um processo de Wiener no intervalo \(0\leq t \leq 1.\) Podem ser construídos através de uma família \(\{Z_d^{(n)}\}_{d\in D, n\in \mathbb{N}}\) de processos independentes normais, com \(Z_d^{(n)} \sim \mathcal{N}(0, 1)\) e \(Z_0^{(n)} = 0 \sim \mathcal{N}(0, 0),\) com espaço amostral \(\tilde\Omega = \Omega^{\mathbb{N}} = \mathbb{R}^{D^{\mathbb{N}}}.\)</p>
<p>Definimos cada \(\{W_t^{(n)}\}_{0 \leq t \leq 1}\) a partir de \(\{Z_d^{(n)}\}_{d\in D}\) e, em seguida, concatenamo-los através da fórmula</p>
\[
W_t = \sum_{k = 1}^{[t]} W_1^k + W_{t - [t]}^{[t]+1}, \qquad \forall t \geq 0,
\]
<p>onde \([t] = \max\{n \leq t, n \in \mathbb{Z}\}\) é o maior inteiro menor do que \(t \geq 0.\)</p>
<p>Isso define um processo estocástico contínuo com todos as condições necessárias para ser um processo de Wiener. A demonstração disso fica como exercício.</p>
<h2 id="exercícios"><a href="#exercícios" class="header-anchor">Exercícios</a></h2>
<ol>
<li><p>Faça os detalhes da demonstração por indução de que os processos contínuos definidos por</p>
</li>
</ol>
\[
W_t^{(n+1)} = W_t^{(n)} + \sum_{d\in D_{n+1}\setminus D_n} s_d(t)Z_d = \sum_{d\in D_{n+1}} s_d(t)Z_d
\]
<p>são interpolações dos processos discretos \(\{X_d^{(n)}\}_{d\in D_n},\) i.e. \(W_d^{(n)} = X_d^{(n)},\) para todo \(d\in D_n\) e todo \(n\in\mathbb{N}.\)</p>
<ol start="2">
<li><p>Sejam \(\{W_t^k\}_{t \in [0, 1]},\) \(k\in \mathbb{N},\) processos de Wiener, em \([0, 1],\) independentes. Faça os detalhes da demonstração de que \(W_t = \sum_{k = 1}^{[t]} W_1^k + W_{t - [t]}^{[t]+1}\) é um processo de Wiener em \([0, \infty).\)</p>
</li>
<li><p>Na construção, definimos \(X_{d}^{n+1},\) para \(d \in D_{n+1}\setminus D_n,\) pela fórmula \((X_{d - 1/2^n}^{(n)} + X_{d + 1/2^n}^{(n)})/2 + Z_d/2^{(n + 1)/2},\) com os \(Z_d\)&#39;s sendo mutamente independentes. Essa construção não é arbitrária. Mostre que se \(\{W_t\}_{t\geq 0}\) é um processo de Wiener e \(0 \leq s < t,\) então</p>
</li>
</ol>
\[
W_{(t + s)/2} - \frac{W_s + W_t}{2}
\]
<p>é independente de \(W_\tau,\) para \(\tau \leq s\) e para \(\tau \geq t.\)</p>
<ol start="4">
<li><p>Além de pontos médios, mostre, usando a independência de incrementos disjuntos, que \(W_t - tW_1\) e \(W_1\) são mutuamente independentes, para \(0 < t < 1.\)</p>
</li>
</ol>

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c05/definicao_processo_wiener">5.1. Definição <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c05/propriedades_wiener"><kbd>→</kbd> 5.3. Propriedades de processos de Wiener</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: November 04, 2024. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    
        <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>
    

  </body>
</html>
