<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Probabilidade condicionada</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações diferenciais aleatórias e estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_browniano">1.3. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_einstein">1.4. O modelo de Einstein para o movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/passeioaleatorio_movbrowniano">1.5. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_bachelier">1.6. O modelo de Bachelier para o mercado de opções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.7. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/simulacoes_intro">1.8. Simulações numéricas de modelos de crescimento natural</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/prob_condicionada">2.5. Probabilidade condicionada</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades fundamentais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/transformacoes">2.8. Transformações de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/convergencias">2.9. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/borel_cantelli">2.10. Lema de Borel-Cantelli</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.11. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. O método de Monte-Carlo</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/monte_carlo">3.1. O método de Monte-Carlo no estudo de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/histograma">3.2. Histograma - estimando a distribuição de probabilidades</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/gerando_num_aleatorios">3.3. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/definicao_pe">4.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_discretos">4.2. Processos em tempos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_continuos">4.3. Processos em tempos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/tipos_processos">4.4. Classes de processos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/filtracao">4.5. Filtração</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/cadeias_markov">4.6. Processos de Markov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/continuity_kolmogorov">4.7. Teorema de Continuidade de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li>5. Processos de Wiener</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/definicao_processo_wiener">5.1. Definição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/existencia_processo_wiener">5.2. Existência de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/propriedades_wiener">5.3. Propriedades de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/ruido_branco">5.4. Relação com ruído branco</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/simetrias_wiener">5.5. Simetrias de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/naodiferenciabilidade_wiener">5.6. Não diferenciabilidade quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/variacao_ilimitada_wiener">5.7. Variação ilimitada dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-1">
    <li>6. Integração estocástica</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemann">6.1. Integrais de Riemann</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemannstieltjes">6.2. Integrais de Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_dualidade">6.3. Integrais via dualidade</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/riemann_wiener">6.4. Limites de somatórios à la Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito">6.5. Integral de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito_propriedades">6.6. Propriedades da integral de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/formula_ito">6.7. Fórmula de Itô</a></li>
    </div>
    <div class="menu-level-1">
    <li>7. Equações diferenciais aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/existence_solutions_rde">7.1. Existência e unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/basic_examples_rde">7.2. Exemplos básicos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/logistic_rde">7.3. Equação logística aleatória</a></li>
    </div>
    <div class="menu-level-1">
    <li>8. Equações diferenciais estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/setting">8.1. Interpretação da equação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde_particulares">8.2. Existência de soluções locais em casos particulares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde">8.3. Existência de soluções globais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/unicidade_sol_sde">8.4. Unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/continuidade_caminhos">8.5. Limitação e continuidade das soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/linear_sde">8.6. Resolução de equações lineares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/geometric_brownian">8.7. Movimento Browniano geométrico e o preço de ações</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/brownian_bridge">8.8. Ponte Browniana</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/ornstein_uhlenbeck">8.9. O processo de Ornstein-Uhlenbeck e a equação de Langevin</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/feynmann_kac">8.10. Fórmula de Feynman-Kac</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/asymptotic_stability">8.11. Estabilidade assintótica</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/relacoes_rode_sde">8.12. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>9. Métodos numéricos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/tx_convergencia">9.1. Convergências forte e fraca</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/simulacoes_wiener">9.2. Simulações de processos de Wiener e browniano geométrico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/convergencia_euler_maruyama">9.3. Convergência forte do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/nao_convergencia_euler_maruyama">9.4. Não convergência do método de Euler-Maruyama sem condição Lipschitz global</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/simulacoes_convergencia_em">9.5. Simulações ilustrando ordem de  convergência do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/heun">9.6. Método de Heun</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/simulacoes_convergencia_randomheun">9.7. Simulações ilustrando ordem de convergência do método de Heun</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/milstein">9.8. O método de Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/simulacoes_milstein">9.9. Simulações Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/convergencia_fraca_em">9.10. Convergência fraca do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/sciml">9.11. O ambiente SciML da linguagem Julia</a></li>
    </div>
    <div class="menu-level-1">
    <li>10. Evolução da função densidade de probabilidade</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/deterministic">10.1. Equação do transporte no caso de equações diferenciais ordinárias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/stochastic">10.2. Equação de Fokker-Planck no caso de equações estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/stationaryOU">10.3. Distribuição assintótica estacionária dos processos de Ornstein-Uhlenbeck</a></li>
    </div>
    <div class="menu-level-2">
    <li>10.4. Métodos numéricos</li>
    </div>
    <div class="menu-level-1">
    <li>11. Sistemas de equações aleatórias</li>
    </div>
    <div class="menu-level-1">
    <li>12. Sistemas de equações estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/nuclear_reactions">12.1. Reações nucleares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir">12.2. Modelo SIR estocástico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir_network">12.3. Modelo SIR estocástico estruturado em rede</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_extension_kolmogorov">Teorema de Extensão de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/desigualdades"><kbd>→</kbd> 2.6. Desigualdades fundamentais</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">2.5. Probabilidade condicionada</a></h1>
<p>O conceito de probabilidade condicionada é fundamental. Invariavelmente, quando queremos saber a probabilidade de um determinado evento acontecer, temos outras informações à nossa disposição que podemos aproveitar.</p>
<h2 id="conceito"><a href="#conceito" class="header-anchor">Conceito</a></h2>
<p>A probabilidade condicionada diz respeito à probabilidade de um determinado evento ser realizado, assumindo-se a realização de um outro evento. A probabilidade de um determinado evento \(A\) dado a realização de um outro evento \(B\) é denotada por</p>
\[
P(A | B).
\]
<p>Note que isso é diferente da probabilidade conjunta \(A \cap B\). De fato, se \(A\) for o espaço \(\Omega\) todo, então a probabilidade de \(\Omega\) deve ser um. Ou seja, \(\mathbb{P}(\Omega | B) = 1\). Por outro lado, \(\mathbb{P}(\Omega \cap B) = \mathbb{P}(B)\).</p>
<p>Podemos ver a probabilidade condicionada a um evento \(B\) como uma fração da probabilidade do evento \(B\) ocorrer:</p>
\[
\mathbb{P}(A | B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}.
\]
<p>É claro que é necessário que \(\mathbb{P}(B) > 0\) para essa fórmula valer. Essa fórmula é conhecida como a <strong>lei da probabilidade condicionada.</strong></p>
<p>A definição, propriamente, de probabilidade condicionada é bem mais delicada. Veremos isso posteriormente. No momento, vamos seguir com a intuição.</p>
<h2 id="exemplos"><a href="#exemplos" class="header-anchor">Exemplos</a></h2>
<p>Seja \(X\) uma variável aleatória com distribuição uniforme em \(\Sigma = \{1, 2, \ldots, 9\}\). Desses, \(\{2, 4, 6, 8\}\) são pares e \(\{3, 6, 9\}\) são múltiplos de \(3\). Assim,</p>
\[
\mathbb{P}(X \textrm{ é par}) = \frac{4}{9}, \quad \mathbb{P}(X \textrm{ é múltiplo de 3}) = \frac{3}{9} = \frac{1}{3}, \quad \mathbb{P}(X \textrm{ é par e múltiplo de 3}) = \frac{1}{9}.
\]
<p>Agora, sabendo-se que \(X\) é múltiplo de \(3\), quais as chances de \(X\) ser par? Naturalmente, temos uma única possibilidade em três: \(\{6\}\) em \(\{3, 6, 9\}\), ou seja,</p>
\[
\mathbb{P}(X \textrm{ é par } | X \textrm{ é múltiplo de 3}) = \frac{1}{3}.
\]
<p>Podemos obter esse mesmo resultado através da lei da probabilidade condicionada:</p>
\[
\mathbb{P}(X \textrm{ é par } | X \textrm{ é múltiplo de 3}) = \frac{\mathbb{P}(X \textrm{ é par e múltiplo de 3})}{\mathbb{P}(X \textrm{ é múltiplo de 3})} = \frac{\displaystyle\frac{1}{9}}{\displaystyle\frac{1}{3}} = \frac{3}{9} = \frac{1}{3}.
\]
<p>E quais as chances de \(X\) ser múltiplo de três dado que é par?</p>
<p>Um outro exemplo importante em que podemos usar probabilidade condicionada é em testes clínicos, como a da eficácia de vacinas, que ficou tanto em evidência com a Covid-19. Considere um certo número de voluntários, digamos 1000, envolvidos em um certo ensaio clínico. Desses, 500 seguem o tratamento e 500 tomam placebo. Dos que tomam placebo, 20 desenvolvem sintomas da doença. Dos que seguem o tratamento, apenas 5 desenvolvem sintomas. Isso pode ser representado pela tabela a seguir.</p>
<table><tr><th align="left"></th><th align="center">adoecem &#40;A&#41;</th><th align="center">não adoecem</th></tr><tr><td align="left">tratamento &#40;B&#41;</td><td align="center">5</td><td align="center">495</td></tr><tr><td align="left">placebo</td><td align="center">40</td><td align="center">460</td></tr></table>
<p>No total, temos \(1000\) voluntários, sendo que \(25\) desse total adoecem e apenas \(5\) seguem o tratamento e adoecem. Denotando por \(A\) o evento de adoecer e por \(B\) o de seguir o tratamento, podemos escrever</p>
\[
\mathbb{P}(A \cap B) = \frac{5}{1000}, \quad \mathbb{P}(B) = \frac{500}{1000}.
\]
<p>Com isso, podemos obter a probabilidade de alguém adoecer fazendo o tratamento:</p>
\[
\mathbb{P}(A | B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} = \frac{\displaystyle \frac{5}{1000}}{\displaystyle \frac{500}{1000}} = \frac{5}{500} = 1\%.
\]
<p>Também podemos visualizar isso completando a tabela com os totais:</p>
<table><tr><th align="left"></th><th align="center">adoecem &#40;A&#41;</th><th align="center">não adoecem</th><th align="center">total</th></tr><tr><td align="left">tratamento &#40;B&#41;</td><td align="center">5</td><td align="center">495</td><td align="center">500</td></tr><tr><td align="left">placebo</td><td align="center">40</td><td align="center">460</td><td align="center">500</td></tr><tr><td align="left">total</td><td align="center">45</td><td align="center">975</td><td align="center">1000</td></tr></table>
<p>Vemos, diretamente, na primeira coluna, que \(5\) adoceram dentre os \(500\) que fizeram o tratamento, ou seja, há \(5/500 = 1\%\) de chance de adoecer se seguirmos o tratamento. Da mesma forma, sem tratamento, temos \(40/500 = 8\%\) de chances de adoecer. Nesse caso, podemos dizer que o tratamento reduziu de \(8\%\) a \(1\%\) as chances de adoecer. Ou seja, houve uma redução relativa de \((8\% - 1\%)/8\% = 7/8 = 87,5\%\).</p>
<h2 id="eventos_independentes"><a href="#eventos_independentes" class="header-anchor">Eventos independentes</a></h2>
<p>Quando as chances de um evento \(A\) acontecer independem de um outro evento \(B\), podemos expressar isso por</p>
\[
\mathbb{P}(A | B) = \mathbb{P}(A).
\]
<p>Essa propriedade é recíproca, ou seja, \(A\) independe de \(B\) se, e somente se, \(B\) independe de \(A\), com</p>
\[
\mathbb{P}(B | A) = \mathbb{P}(B).
\]
<p>Observe que, pela lei da probabilidade condicionada, se \(\mathbb{P}(B) > 0\), então, que</p>
\[
\mathbb{P}(A) = \mathbb{P}(A | B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)},
\]
<p>ou seja, assumindo-se \(\mathbb{P}(B) > 0\), temos a caracterização</p>
\[
\mathbb{P}(A | B) = \mathbb{P}(A) \quad \Leftrightarrow \quad \mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B).
\]
<p>Da mesma forma, se \(\mathbb{P}(A) > 0\), então, </p>
\[
\mathbb{P}(B | A) = \mathbb{P}(B) \quad \Leftrightarrow \quad \mathbb{P}(B \cap A) = \mathbb{P}(B)\mathbb{P}(A).
\]
<p>Em particular, se \(\mathbb{P}(A), \mathbb{P}(B) > 0\), então</p>
\[
\mathbb{P}(A | B) = \mathbb{P}(A) \quad \Leftrightarrow \quad \mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B) \quad \Leftrightarrow \quad \mathbb{P}(B | A) = \mathbb{P}(B).
\]
<p>Por exemplo, as chances do resultado de um dado não viciado de seis faces dar um número menor ou igual a quatro é independente do número ser par ou ímpar e é sempre igual a dois terços. Já as chances do número ser menor ou igual a três depende: é igual a meio, se não soubermos a sua paridade, é igual a um terço, se o número for par, é igual a dois terços, se o número for ímpar.</p>
<h2 id="lei_da_probabilidade_total"><a href="#lei_da_probabilidade_total" class="header-anchor">Lei da probabilidade total</a></h2>
<p>Um resultado importante em probabilidade pode ser interpretado como uma estratégia de <em>dividir para conquistar</em>. Digamos que \(\mathbb{P}\) seja uma medida de probabilidade em um espaço amostral \(\Omega\). Suponha que queiramos saber a medida de um determinado conjunto \(A\). Suponha, ainda, que seja razoável dividir o espaço em subconjuntos disjuntos \(B_1, \ldots, B_k\), ou seja, \(\Omega = \cup_{j = 1}^k B_j\) e \(B_i \cap B_j = \emptyset\), \(i\neq j\), \(i, j = 1, \ldots, k\). Então, vale a <strong>lei da probabilidade total</strong></p>
\[
\mathbb{P}(A) = \mathbb{P}(A \cap B_1) + \ldots + \mathbb{P}(A \cap B_k).
\]
<p>Juntando com a lei da probabilidade condicionada, podemos escrever</p>
\[
\mathbb{P}(A) = \mathbb{P}(A | B_1)\mathbb{P}(B_1) + \ldots + \mathbb{P}(A | B_k)\mathbb{P}(B_k).
\]
<p>Considerando, novamente, a variável aleatória uniformemente distribuída nos dígitos \(\{1, 2, \ldots, 9\}\), temos</p>
\[
\mathbb{P}(X \textrm{ é múltiplo de 3}) = \mathbb{P}(X \textrm{ é par múltiplo de 3}) + \mathbb{P}(X \textrm{ é ímpar múltiplo de 3}) = \frac{1}{9} + \frac{2}{9} = \frac{3}{9} = \frac{1}{3}.
\]
<p>Ou, usando probabilidade condicionada,</p>
\[
\begin{align*}
\mathbb{P}(X \textrm{ é múltiplo de 3})
& = \mathbb{P}(X \textrm{ é múltiplo de 3} | X \textrm{ é par })\mathbb{P}(X \textrm{ é par}) \\
& \qquad + \mathbb{P}(X \textrm{ é múltiplo de 3} | X \textrm{ é ímpar })\mathbb{P}(X \textrm{ é ímpar}) \\
& = \frac{1}{4}\times\frac{4}{9} + \frac{2}{5}\times\frac{5}{9} = \frac{1}{9} + \frac{2}{9} \\
& = \frac{1}{3}.
\end{align*}
\]
<p>Seguindo na linha de ensaios clínicos, digamos que haja um novo teste para a detecção de alguma doença endêmica que, estima-se, atinge 1&#37; da população. Ensaios clínicos indicam que o teste possui 96&#37; de acerto, ou seja, que, em cada 100 pessoas com a doença, o teste dá resultado positivo em 96 delas. E que ele tem 0,1&#37; de falsos positivos. Ou seja, de cada 1000 pessoas sem a doença, o teste dá positivo em 1 delas. Se uma pessoa qualquer faz o teste, quais as chances dela testar positivo, independentemente de ter ou não a doença?</p>
<p>Vejamos. Se \(D\) indica o evento de se ter a doença e \(P\), do evento do teste dar positivo, a lei da probabilidade total nos diz que</p>
\[
\mathbb{P}(P) = \mathbb{P}(P | D)\mathbb{P}(D) + \mathbb{P}(P | \neg D)\mathbb{\neg D},
\]
<p>onde \(\neg D\) é o complemento de \(D\), ou seja, nesse caso, representa não ter a doença. As informações nos dizem que</p>
\[
\mathbb{P}(P | D) = 0.96, \qquad \mathbb{P}(P | \neg D) = 0.001, \qquad \mathbb{P}(D) = 0.01.
\]
<p>Além disso,</p>
\[
\mathbb{P}(\neg D) = 1 - \mathbb{P}(A) = 0.99.
\]
<p>Portanto, as chances de uma pessoa qualquer testar positivo é de</p>
\[
\mathbb{P}(P) = 0.96 \times 0.01 + 0.001 \times 0.99 = 0.01059.
\]
<p>Ou seja, as chances de uma pessoa qualquer testar positivo são de 1,059&#37;.</p>
<h2 id="teorema_de_bayes"><a href="#teorema_de_bayes" class="header-anchor">Teorema de Bayes</a></h2>
<p>Dados dois eventos \(A\) e \(B\) com probabilidade positiva, temos que</p>
\[
\mathbb{P}(A | B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}
\]
<p>e</p>
\[
\mathbb{P}(B | A) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(A)}.
\]
<p>Substituindo, na primeira identidade, a expressão para \(\mathbb{P}(A \cap B)\) obtida da segunda identidade, obtemos o resultado do <strong>Teorema de Bayes:</strong></p>
\[
\mathbb{P}(A | B) = \frac{\mathbb{P}(B | A)\mathbb{P}(A)}{\mathbb{P}(B)}.
\]
<p>O Teorema de Bayes tem inúmeras aplicações. Pensemos, novamente, no exemplo do ensaio clínico acima, de um teste com 96&#37; de acerto para alguma doença endêmica que atinge 1&#37; da população, com 0,1&#37; de falsos positivos. Se uma pessoa qualquer testar positivo, quais as chances dela realmente estar com a doença?</p>
<p>Vejamos. Se \(D\) indica o evento de se ter a doença e \(T\), o evento do teste dar positivo, então a probabilidade de se ter a doença dado que o teste deu positivo é representada por \(\mathbb{P}(D | T)\). De acordo com o Teorema de Bayes, </p>
\[
\mathbb{P}(D | T) = \frac{\mathbb{P}(T | D)\mathbb{P}(D)}{\mathbb{P}(T)}.
\]
<p>Sabemos que \(\mathbb{P}(T | D) = 0.96\) e que \(\mathbb{P}(D) = 0.01\). Vimos, também, usando a lei da probabilidade total, que \(\mathbb{P}(T) = 0.01059\). Logo,</p>
\[
\mathbb{P}(A | B) = \frac{0.96 \times 0.01}{0.01059} \approx 0.9065
\]
<p>Ou seja, as chances de alguém que testou positivo realmente ter a doença são de 90,65&#37;.</p>
<h2 id="exercício"><a href="#exercício" class="header-anchor">Exercício</a></h2>
<ol>
<li><p>Mostre, na lei da probabilidade total, que basta que \(\mathbb{P}(B_1 \cup \cdots \cup B_k) = 1\) e \(\mathbb{P}(B_i \cap B_j) = 0\), para \(i, j = 1, \ldots, k\), com \(i \neq j\).</p>
</li>
<li><p>Em um torneio de xadrez, podemos classificar os jogadores em níveis A, B e C. Além de você, há 3 jogadores de nível A, 4 de nível B e 8 de nível C. O seu primeiro oponente é sorteado aleatoriamente dentre esses. As suas chances de vitória são \(\mathbb{P}(\textrm{vitória} | \textrm{oponente nível A}) = 0.5\), \(\mathbb{P}(\textrm{vitória} | \textrm{oponente nível B}) = 0.65\) e \(\mathbb{P}(\textrm{vitória} | \textrm{oponente nível C}) = 0.8\). Quais as suas chances de vitória no primeiro jogo?</p>
</li>
<li><p>No exemplo do teste clínico, suponha, no entanto, que a doença atinge apenas 0,1&#37; da população, mantendo a eficácia do teste em 96&#37; e a taxa de falsos positivos em 0,1&#37;. Encontre as chances de uma pessoa qualquer ser testada positivo e as chances de uma pessoa testada positivo realmente ter a doença. Repita as contas no caso em que a doença atinge 1&#37; e a taxa de falsos positivos sobe para 1&#37;.</p>
</li>
</ol>

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/desigualdades"><kbd>→</kbd> 2.6. Desigualdades fundamentais</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: April 19, 2024. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    

  </body>
</html>
