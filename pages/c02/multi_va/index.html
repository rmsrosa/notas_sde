<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Variáveis aleatórias multivariadas</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações diferenciais aleatórias e estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_browniano">1.3. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_einstein">1.4. O modelo de Einstein para o movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/passeioaleatorio_movbrowniano">1.5. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/modelo_bachelier">1.6. O modelo de Bachelier para o mercado de opções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.7. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/simulacoes_intro">1.8. Simulações numéricas de modelos de crescimento natural</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/prob_condicionada">2.5. Probabilidade condicionada</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades fundamentais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/transformacoes">2.8. Transformações de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/convergencias">2.9. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/borel_cantelli">2.10. Lema de Borel-Cantelli</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.11. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. O método de Monte-Carlo</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/monte_carlo">3.1. O método de Monte-Carlo no estudo de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/histograma">3.2. Histograma - estimando a distribuição de probabilidades</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/gerando_num_aleatorios">3.3. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/definicao_pe">4.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_discretos">4.2. Processos em tempos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/processos_continuos">4.3. Processos em tempos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/tipos_processos">4.4. Classes de processos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/filtracao">4.5. Filtração</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/cadeias_markov">4.6. Processos de Markov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/continuity_kolmogorov">4.7. Teorema de Continuidade de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li>5. Processos de Wiener</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/definicao_processo_wiener">5.1. Definição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/existencia_processo_wiener">5.2. Existência de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/propriedades_wiener">5.3. Propriedades de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/ruido_branco">5.4. Relação com ruído branco</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/simetrias_wiener">5.5. Simetrias de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/naodiferenciabilidade_wiener">5.6. Não diferenciabilidade quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/variacao_ilimitada_wiener">5.7. Variação ilimitada dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/c06/integracao_estocastica">6. Integração estocástica</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemann">6.1. Integrais de Riemann</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_riemannstieltjes">6.2. Integrais de Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_dualidade">6.3. Integrais via dualidade</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/riemann_wiener">6.4. Limites de somatórios à la Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito">6.5. Integral de Itô via processos uniformemente contínuos em média quadrática</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito_l2">6.6. Integral de Itô via processos do tipo escada</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_ito_propriedades">6.7. Propriedades da integral de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/formula_ito">6.8. Fórmula de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/integral_stratonovich">6.9. Integral de Stratonovich</a></li>
    </div>
    <div class="menu-level-1">
    <li>7. Equações diferenciais aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/existence_solutions_rde">7.1. Existência e unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/basic_examples_rde">7.2. Exemplos básicos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c07/logistic_rde">7.3. Equação logística aleatória</a></li>
    </div>
    <div class="menu-level-1">
    <li>8. Equações diferenciais estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/setting">8.1. Interpretação da equação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde_particulares">8.2. Existência de soluções locais em casos particulares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/existence_solutions_sde">8.3. Existência de soluções globais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/unicidade_sol_sde">8.4. Unicidade de soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/continuidade_caminhos">8.5. Limitação e continuidade das soluções</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/linear_sde">8.6. Resolução de equações lineares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/geometric_brownian">8.7. Movimento Browniano geométrico e o preço de ações</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/brownian_bridge">8.8. Ponte Browniana</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/ornstein_uhlenbeck">8.9. A equação de Langevin e o processo de Ornstein-Uhlenbeck</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/ou_aproxima_ruidobranco">8.10. O processo de Ornstein-Uhlenbeck como aproximação de um ruído branco</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/asymptotic_stability">8.11. Estabilidade assintótica</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c08/relacoes_rode_sde">8.12. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>9. Evolução da função densidade de probabilidade</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/deterministic">9.1. Equação do transporte para equações diferenciais ordinárias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/stochastic">9.2. Equação de Fokker-Planck para equações diferenciais estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/stationaryOU">9.3. Distribuição assintótica estacionária dos processos de Ornstein-Uhlenbeck</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c09/feynmann_kac">9.4. Fórmula de Feynman-Kac e a equação retrógrada de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li>10. Métodos numéricos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/tx_convergencia">10.1. Convergências forte e fraca</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_wiener">10.2. Simulações de processos de Wiener e browniano geométrico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/convergencia_euler_maruyama">10.3. Convergência forte do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/nao_convergencia_euler_maruyama">10.4. Não convergência do método de Euler-Maruyama sem condição Lipschitz global</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_convergencia_em">10.5. Simulações ilustrando ordem de  convergência do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/heun">10.6. Método de Heun</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_convergencia_randomheun">10.7. Simulações ilustrando ordem de convergência do método de Heun para equações diferenciais aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/milstein">10.8. O método de Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/simulacoes_milstein">10.9. Simulações Milstein</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/convergencia_fraca_em">10.10. Convergência fraca do método de Euler-Maruyama</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c10/sciml">10.11. O ambiente SciML da linguagem Julia</a></li>
    </div>
    <div class="menu-level-1">
    <li>11. Sistemas de equações aleatórias</li>
    </div>
    <div class="menu-level-1">
    <li>12. Sistemas de equações estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/nuclear_reactions">12.1. Reações nucleares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir">12.2. Modelo SIR estocástico</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c11/stochastic_sir_network">12.3. Modelo SIR estocástico estruturado em rede</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_extension_kolmogorov">Teorema de Extensão de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades fundamentais <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/transformacoes"><kbd>→</kbd> 2.8. Transformações de variáveis aleatórias</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">2.7. Variáveis aleatórias multivariadas</a></h1>
<p>As coisas começam a ficar mais interessantes quando consideramos mais de uma variável aleatória. Para que elas sejam consideradas juntas, é necessário que estejam definidas em um mesmo espaço de probabilidades. Isso aparece de forma natural, como veremos aqui.</p>
<h2 id="variáveis_aleatórias_multivariadas"><a href="#variáveis_aleatórias_multivariadas" class="header-anchor">Variáveis aleatórias multivariadas</a></h2>
<p>Uma maneira de pensar uma coleção de variáveis aleatórias é como um vetor \(X = (X_1, \ldots, X_n)\) &#40;muitas vezes se considera um vetor coluna, na verdade&#41; cujos elementos estão em um mesmo espaço de probabilidades, digamos \((\Omega, \mathcal{A}, \mathbb{P}).\) Os espaços de eventos podem ser diferentes, de forma que \(\Sigma = \Sigma_1 \times \cdots \times \Sigma_n,\) com a \(\sigma\)-algebra \(\mathcal{E}\) gerada por \(\mathcal{E}_1 \times \cdots \times \mathcal{E}_n.\) Tal objeto é chamado de <strong>variável aleatória multivariada.</strong> E a probabilidade \(\mathbb{P}\) é chamada de <strong>distribuição conjunta de probabilidades.</strong></p>
<p>A partir da probabilidade conjunta, podemos obter as chances de certas combinações de eventos \(E \in \mathcal{E}\) acontecerem:</p>
\[
\mathbb{P}(X \in E).
\]
<p>Quando o evento conjunto é da forma \(E = E_1 \times \ldots \times E_n,\) podemos escrever</p>
\[
\mathbb{P}(X_1 \in E_1, \ldots, X_n \in E_n)
\]
<p>Também podemos extrair a probabilidade de realização de um evento para apenas uma das variáveis, que é chamada de <strong>marginal</strong>.</p>
\[
\mathbb{P}(X_i \in E_i).
\]
<p>Isso pode ser obtido da distribuição conjunta, considerando o evento \(\mathbb{E} = \Sigma_1 \times \ldots \Sigma_{i-1}\times E_i \times \Sigma_{i+1} \times \cdot \times \Sigma_n.\)</p>
<h2 id="exemplo"><a href="#exemplo" class="header-anchor">Exemplo</a></h2>
<p>Por exemplo, considere um dado de quatro lados e um de seis. Ambos dados não viciados. Há \(4 \times 6 = 24\) combinações possíveis. O espaço amostral \(\Omega\) deverá ter &#40;pelo menos&#41; 24 elementos, cada combinação com uma determinada probabilidade.</p>
<p>Podemos representar os resultado dos dados através de duas variáveis aleatórias, digamos \(X\) e \(Y,\) com \(X\) para o resultado do lançamento do dado de quatro lados e \(Y,\) para o de seis. Isoladamente, teríamos um espaço amostral de quatro elementos para \(X\) e um de seis para \(Y.\) Mas em conjunto, temos uma variável multivariada \((X, Y)\) em um espaço amostral de 24 elementos. Mais explicitamente, podemos considerar</p>
\[
\Omega = \Sigma = \{1, \ldots, 4\} \times \{1, \ldots, 6\}.
\]
<p>A probabilidade conjunta \(\mathbb{P}\) é o que define a variável multivariada nos dando as probabilidades das realizações de cada combinação:</p>
\[
\mathbb{P}(X = i, Y = j) = \frac{1}{24}, \qquad i = 1, \ldots, 4, \;j = 1, \ldots, 6.
\]
<p>A partir daí, podemos tirar as marginais:</p>
\[
\mathbb{P}(X = i) = \frac{1}{4}, \quad i = 1, \ldots, 4, \qquad \mathbb{P}(Y = j) = \frac{1}{6}, \quad j = 1, \ldots, 6.
\]
<p>As marginais podem ser obtidas com a lei da probabilidade total, por exemplo,</p>
\[
\mathbb{P}(X = i) = \sum_{j = 1}^6 \mathbb{P}(X = i, Y = j) = \sum_{j = 1}^6 \frac{1}{24} = \frac{6}{24} = \frac{1}{4}.
\]
<h2 id="independência"><a href="#independência" class="header-anchor">Independência</a></h2>
<p>Duas variáveis aleatórias \(X\) e \(Y\) gerando uma variável aleatória multivariada \((X, Y)\) em um espaço \((\Omega, \mathcal{A}, \mathbb{P})\) são ditas <strong>independentes</strong> quando a probabilidade conjunta é o produto das marginais:</p>
\[
\mathbb{P}(X \in E_1, Y \in E_2) = \mathbb{P}(X \in E_1)\mathbb{P}(X \in E_2).
\]
<p>No caso de uma variável multivariada \((X_1, \ldots, X_n),\) dizemos que as variáveis \(X_i\) são <strong>&#40;mutuamente&#41; independentes</strong> quando</p>
\[
\mathbb{P}(X_1 \in E_1, \ldots, X_n \in E_n) = \mathbb{P}(X_1 \in E_1)\cdots \mathbb{P}(X_n \in E_n).
\]
<p>Analogamente no caso de uma coleção infinita \(\{X_k\}_k\) &#40;enumerável ou não&#41; de variáveis aleatórias em um mesmo espaço.</p>
<p>Essa propriedade pode ser usada diretamente na construção de variáveis multivariadas independentes&#33;</p>
<h2 id="independência_dois_a_dois"><a href="#independência_dois_a_dois" class="header-anchor">Independência dois a dois</a></h2>
<p>Dizemos que variáveis aleatórias \(X_1, \ldots, X_n\) definindo uma variável multivariada \((X_1, \ldots, X_n)\) são <strong>independentes duas a duas</strong> quando qualquer par \((X_i, X_j)\) é independente, i.e.</p>
\[
\mathbb{P}(X_i \in E_i, X_j \in E_j) = \mathbb{P}(X_i \in E_i)\mathbb{P}(X_j \in E_j), \qquad \forall i \neq j.
\]
<p>Observe que podemos ter um conjunto com mais de duas variáveis aleatórias cujas variáveis sejam independentes dois a dois, mas não mutuamente. De fato, considere três variáveis aleatórias \(X,\) \(Y\) e \(Z,\) onde \(X\) e \(Y\) são variáveis de Bernoulli independentes, com probabilidade de sucesso \(p = 1/2,\) e defina \(Z\) como sendo \(1,\) caso os resultados de \(X\) e \(Y\) sejam diferentes, e \(0,\) caso os resultados sejam iguais. Podemos escrever isso como \(Z = X + Y \mod 2,\) com \(X\) e \(Y\) assumindo valores \(0\) ou \(1.\) Podemos pensar nisso como um <em>checksum</em> simples, ou um dígito verificador.</p>
<p>Nesse caso, \(X\) e \(Y\) são independentes, \(X\) e \(Z\) são independentes e \(Y\) e \(Z\) são independentes. Mas \(X, Y\) e \(Z\) não são mutuamente independentes, já que \(Z\) está completamente determinado pelos resultados de \(X\) e \(Y.\)</p>
<p>Podemos mostrar isso mais explicitamente, através da distribuição conjunta de probabilidade, até mesmo para solidificar as ideias acima. A tabela abaixo nos dá a distribuição conjunta de probabilidades:</p>
<table><tr><th align="center">X</th><th align="center">Y</th><th align="center">Z</th><th align="left">Probabilidade</th></tr><tr><td align="center">0</td><td align="center">0</td><td align="center">0</td><td align="left">1/4</td></tr><tr><td align="center">1</td><td align="center">0</td><td align="center">1</td><td align="left">1/4</td></tr><tr><td align="center">0</td><td align="center">1</td><td align="center">0</td><td align="left">1/4</td></tr><tr><td align="center">1</td><td align="center">1</td><td align="center">1</td><td align="left">1/4</td></tr></table>
<p>O espaço amostral pode ser tomado como sendo \(\Omega = \{0, 1\}^3.\) Acima, só mostramos as combinações com probabilidade positiva. Mas podemos completar o quadro:</p>
<table><tr><th align="center">X</th><th align="center">Y</th><th align="center">Z</th><th align="left">Probabilidade</th></tr><tr><td align="center">0</td><td align="center">0</td><td align="center">0</td><td align="left">1/4</td></tr><tr><td align="center">0</td><td align="center">0</td><td align="center">1</td><td align="left">0</td></tr><tr><td align="center">1</td><td align="center">0</td><td align="center">0</td><td align="left">0</td></tr><tr><td align="center">1</td><td align="center">0</td><td align="center">1</td><td align="left">1/4</td></tr><tr><td align="center">0</td><td align="center">1</td><td align="center">0</td><td align="left">0</td></tr><tr><td align="center">0</td><td align="center">1</td><td align="center">1</td><td align="left">1/4</td></tr><tr><td align="center">1</td><td align="center">1</td><td align="center">0</td><td align="left">1/4</td></tr><tr><td align="center">1</td><td align="center">1</td><td align="center">1</td><td align="left">0</td></tr></table>
<p>Observe que</p>
\[
\mathbb{P}(X = 0) = \mathbb{P}(Y = 0) = \mathbb{P}(Z = 0) = \frac{1}{4} + \frac{1}{4} = \frac{1}{2}
\]
<p>No entanto,</p>
\[
\mathbb{P}(X = 0, Y = 0, Z = 0) = 0 \neq \mathbb{P}(X = 0)\mathbb{P}(Y = 0)\mathbb{P}(Z = 0).
\]
<p>Da mesma forma, pode-se verificar que as variáveis são independentes duas a duas.</p>
<h2 id="desigualdade_maximal_de_kolmogorov"><a href="#desigualdade_maximal_de_kolmogorov" class="header-anchor">Desigualdade maximal de Kolmogorov</a></h2>
<p>Como uma aplicação interessante, considere \(n\) variáveis aleatórias independentes \(X_1, \ldots, X_n\) com \(\mathbb{E}[X_k] = 0,\) \(k = 1, \ldots, n,\) e defina</p>
\[
    S_k = \sum_{j=1}^k X_j,
\]
<p>com \(S_0 = 0.\) Estamos interessados em estimar</p>
\[
    \mathbb{P}\left(\max_{1\leq k \leq n} \{S_k\} \geq r\right),
\]
<p>para \(r \geq 0\) arbitrário. Para isso, usamos a decomposição</p>
\[
    \left\{\max_{1\leq k \leq n} \{S_k\} \geq r\right\} = \left\{S_1 \geq r\right\} \bigcup \left\{S_1 < r, S_2 \geq r\right\} \bigcup \cdots \bigcup \left\{S_1 < r, \ldots S_{n-1} < r, S_n \geq r\right\}.
\]
<p>Denotamos</p>
\[
    A_k = \left\{S_1 < r, \ldots S_{k-1} < r, S_k \geq r \right\}.
\]
<p>Como as uniões são disjuntas,</p>
\[
    \mathbb{P}\left(\max_{1\leq k \leq n} \{S_k\} \geq r\right) = \mathbb{P}\left(A_1\right) + \mathbb{P}\left(A_2\right) + \cdots + \mathbb{P}\left(A_n\right)
\]
<p>Usando a desigualdade de Chebyshev,</p>
\[
    \mathbb{P}\left(A_k\right) = \mathbb{E}[\chi_{A_k}] \leq \frac{1}{r^2}\mathbb{E}[S_k^2 \chi_{A_k}] \leq \frac{1}{r^2} \mathbb{E}[(S_k^2 + (S_n - S_k)^2) \chi_{A_k}].
\]
<p>Como as variáveis \(X_k,\) \(k=1, \ldots, n,\) são independentes, temos que</p>
\[
S_k=\sum_{1\leq j \leq k} X_j \qquad \textrm{e} \qquad  S_n - S_k = \sum_{k < j \leq n} X_j
\]
<p>são independentes entre si. Além disso, \(\chi_{A_k}\) só envolve os processos \(X_1, \ldots, X_k,\) sendo também independente de \(S_n - S_k.\) Desse modo,</p>
\[
    \mathrm{Cov}\left(S_k\chi_{A_k}, S_n - S_k\right) = 0
\]
<p>e</p>
\[
    \mathbb{E}[S_k\chi_{A_k}(S_n - S_k)] = \mathrm{Cov}\left(S_k\chi_{A_k}, S_n - S_k\right) + \mathbb{E}\left[S_k\chi_{A_k}\right]\mathbb{E}\left[S_n - S_k\right] = \mathbb{E}\left[S_k\chi_{A_k}\right]\mathbb{E}\left[S_n - S_k\right].
\]
<p>Observe que \(S_k \geq r\) em \(A_k,\) logo</p>
\[
    \mathbb{E}\left[S_k\chi_{A_k}\right] \geq r,
\]
<p>mas</p>
\[
    \mathbb{E}\left[S_n - S_k\right] = 0,
\]
<p>de maneira que</p>
\[
    \mathbb{E}[S_k\chi_{A_k}(S_n - S_k)] = 0.
\]
<p>Assim, podemos completar os quadrados e escrever</p>
\[
\begin{align*}
    \mathbb{E}[(S_k^2 + (S_n - S_k)^2) \chi_{A_k}] & = \mathbb{E}[(S_k^2 + 2S_k(S_n - S_k) + (S_n - S_k)^2)\chi_{A_k}] \\
    & = \mathbb{E}[(S_k + (S_n - S_k))^2\chi_{A_k}] \\
    & = \mathbb{E}[S_n^2\chi_{A_k}].
\end{align*}
\]
<p>Desta forma,</p>
\[
    \mathbb{P}\left(\max_{1\leq k \leq n} \{S_k\} \geq r\right) \leq \frac{1}{r^2}\left( \mathbb{E}[S_n^2\chi_{A_1}] + \cdots + \mathbb{E}[S_n^2\chi_{A_n}]\right) = \frac{1}{r^2}\mathbb{E}[S_n^2\left(\chi_{A_1} + \cdots + \chi_{A_n}\right)].
\]
<p>Como os conjuntos \(A_1, \ldots, A_n\) são disjuntos, temos</p>
\[
    \chi_{A_1} + \ldots + \chi_{A_n} = \chi_{A_1 \cup \cdots \cup A_n} \leq 1,
\]
<p>de modo que</p>
\[
    \mathbb{E}[S_n^2\chi_{A_1 \cup \ldots \cup A_n}] \leq \mathbb{E}[S_n^2].
\]
<p>Como \(S_n\) também tem valor esperado nulo, o lado direito é igual à variância de \(S_n,\) nos levando à desigualdade final, conhecida como <strong>desigualdade de Kolmogorov:</strong></p>
\[
    \mathbb{P}\left(\max_{1\leq k \leq n} \{S_k\} \geq r\right) \leq \frac{1}{r^2}\mathrm{Var}\left(S_n^2\right),
\]
<p>para \(r > 0\) arbitrário.</p>
<h2 id="exercícios"><a href="#exercícios" class="header-anchor">Exercícios</a></h2>
<ol>
<li><p>Considere um vetor aleatório \((X_1, \ldots, X_n)\) como na desigualdade maximal de Kolmogorov, com variáveis independentes e assuma, mais geralmente, que, para um dado \(m\in\mathbb{N},\) os momentos são finitos, i.e. \(\mathbb{E}[X_k^{m}] < \infty,\) \(k=1, \ldots, n,\) e que cada \(X_k\) é simétrico em relação à origem, ou seja, \(X_k\) e \(-X_k\) tem a mesma distribuição. Modifique a demonstração acima da desigualdade maximal de Kolmogorov para obter que</p>
</li>
</ol>
\[
    \mathbb{P}\left(\max_{1\leq k \leq n} \{S_k\} \geq r\right) \leq \frac{1}{r^{m}}\mathbb{E}\left[S_n^{m}\right],
\]
<p>para todo \(r > 0\) e todo inteiro \(m\in\mathbb{N}.\)</p>
<blockquote>
<p><em>Dicas:</em></p>
<p>&#40;i&#41; Substitua a desigualdade de Chebyshev por \( \mathbb{P}\left(A_k\right) = \mathbb{E}[\chi_{A_k}] \leq \frac{1}{r^{m}}\mathbb{E}[S_k^{m} \chi_{A_k}]. \)</p>
<p>&#40;ii&#41; Escreva \( S_n^{m} = (S_k + (S_n - S_k))^{m} = \sum_{i=0}^{m} \left( \begin{matrix} m \\ i \end{matrix}\right)S_k^{m - i}(S_n - S_k)^{i}.\)</p>
<p>&#40;iii&#41; Quando \(i\) é ímpar, segue da simetria de cada \(X_j\) que \(S_n - S_k\) também é simétrico em relação a origem e, portanto, \(\mathbb{E}\left[(S_n - S_k)^i\right] = 0.\) Além disso, \(S_n - S_k\) é independente de \(S_k^{m - i}\chi_{A_k}.\) Assim, \(\mathbb{E}[S_k^{m - i}(S_n - S_k)^{i} \chi_{A_k}] = \mathbb{E}[S_k^{m - i}\chi_{A_k}]\mathbb{E}[(S_n - S_k)^{i}] = 0.\)</p>
<p>&#40;iv&#41; Quando \(i\) é par, temos \((S_n - S_k)^i \geq 0.\) Além disso, \(S_k \geq r > 0\) em \(A_k,\) de modo que \(S_k^{m - i}\chi_{A_k} \geq 0.\) Portanto, \(\mathbb{E}[S_k^{m - i}(S_n - S_k)^{i} \chi_{A_k}] \geq 0.\)</p>
<p>&#40;v&#41; Mantendo apenas o termo \(i=0\) e descartando os outros que se anulam ou são não-negativos, obtemos \(\mathbb{E}[S_n^{m} \chi_{A_k}] \geq \mathbb{E}[S_k^{m}\chi_{A_k}].\)</p>
<p>&#40;vi&#41; Isso nos dá que \(\mathbb{P}\left(A_k\right) = \mathbb{E}[\chi_{A_k}] \leq \frac{1}{r^{m}}\mathbb{E}[S_k^{m} \chi_{A_k}] \leq \frac{1}{r^{m}}\mathbb{E}[S_n^{m} \chi_{A_k}].\)</p>
<p>&#40;vii&#41; Somando em \(k=1, \ldots, n\) e usando que os conjuntos \(A_1, \ldots, A_n\) são disjuntos, como na demonstração acima, obtemos, finalmente, a desigualdade desejada.</p>
</blockquote>
<ol start="2">
<li><p>Sob as condições do exercício anterior, assume, ainda, que \(\mathbb{E}[e^{X_k}] < \infty,\) para todo \(k=1, \ldots, n.\) Mostre que</p>
</li>
</ol>
\[
    \mathbb{P}\left(\max_{1\leq k \leq n} \{S_k\} \geq r\right) \leq e^{-\lambda r}\mathbb{E}\left[e^{\lambda S_n}\right],
\]
<p>para \(r > 0\) e \(\lambda \geq 0\) quaisquer. <em>Dica: use o resultado anterior em uma série de potências.</em></p>

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades fundamentais <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/transformacoes"><kbd>→</kbd> 2.8. Transformações de variáveis aleatórias</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: June 26, 2025. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    

  </body>
</html>
