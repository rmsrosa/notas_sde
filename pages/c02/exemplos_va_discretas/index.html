<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Variáveis aleatórias discretas</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  
    <link rel="stylesheet" href="/notas_sde/libs/highlight/github.min.css">
    <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
    <script src="/notas_sde/libs/highlight/julia.min.js"></script>
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre').forEach((el) => {
          hljs.highlightElement(el);
        });
      });
    </script>
  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações diferenciais aleatórias e estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.3. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/literated/c01/simulacoes_numericas">1.4. Simulações numéricas de modelos de crescimento natural</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_Browniano">1.5. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/passeioaleatorio_movBrowniano">1.6. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/relacoes_rode_sde">1.7. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/prob_condicionada">2.5. Probabilidade condicionada</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades importantes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/transformacoes">2.8. Transformações de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/convergencias">2.9. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/borel_cantelli">2.10. Lema de Borel-Cantelli</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.11. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/gerando_num_aleatorios">2.12. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/definicao_pe">3.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/processos_discretos">3.2. Processos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/processos_continuos">3.3. Processos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/tipos_processos">3.4. Tipos de processos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/filtracao">3.5. Filtração</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/cadeias_markov">3.6. Processos de Markov</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Processos de Wiener</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/definicao_processo_wiener">4.1. Definição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/existencia_processo_wiener">4.2. Existência de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/simetrias_wiener">4.3. Simetrias do processo de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/naodiferenciabilidade_wiener">4.4. Não-diferenciabilidade quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/variacao_ilimitada_wiener">4.5. Variação ilimitada quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/simulacoes_wiener">4.6. Simulações de processos de Wiener</a></li>
    </div>
    <div class="menu-level-1">
    <li>5. Integração estocástica</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/integral_riemann">5.1. Integrais de Riemann</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/integral_riemannstieltjes">5.2. Integrais de Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/integral_dualidade">5.3. Integrais via dualidade</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/riemann_wiener">5.4. Limites de somatórios à la Riemann-Stieltjes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/integral_ito">5.5. Integral de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/integral_ito_propriedades">5.6. Propriedades da integral de Itô</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/formula_ito">5.7. Fórmula de Itô</a></li>
    </div>
    <div class="menu-level-1">
    <li>6. Equações diferenciais aleatórias e estocásticas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/pathwise_solutions_rde">6.1. Soluções por caminhos de equações diferenciais aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/solutions_sde">6.2. Soluções de equações diferenciais estocásticas</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_extension_kolmogorov">Teorema de Extensão de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/exemplos_va_continuas"><kbd>→</kbd> 2.3. Variáveis aleatórias contínuas</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">2.2. Variáveis aleatórias discretas</a></h1>
<p>Uma variável aleatória discreta finita possui um conjunto finito \(\{x_1, \ldots, x_J\}\) de valores possíveis, \(K\in \mathbb{N}\), com probabilidades</p>
\[
\mathbb{P}(X = x_j) = p_j, \quad j = 1, \ldots, J.
\]
<p>O conjunto de probabilidades \(\{p_j\}_j\) é chamada de <strong>função massa de probabilidade</strong> e, naturalmente, cada probabilidade deve ser não-negativa e a soma &#40;massa&#41; total deve ser 1:</p>
\[
0 \leq p_j \leq 1, \qquad \sum_{j=1}^J p_j = 1.
\]
<p>A <strong>função distribuição acumulada</strong> é definida por</p>
\[
  f(x) = \mathbb{P}(X \leq x) = \sum_{x_j \leq x} p_j, \qquad x\in \mathbb{R}.
\]
<p>e nos dá a probabilidade de termos uma realização menor ou igual a um dado valor \(x\).</p>
<p>Vejamos alguns exemplos.</p>
<h2 id="variável_aleatória_uniforme"><a href="#variável_aleatória_uniforme" class="header-anchor">Variável aleatória uniforme</a></h2>
<p>Quando o espaço de estados é finito, digamos \(\Sigma = \{1, 2, \ldots, N\}\), onde \(N\in \mathbb{N}\), uma <strong>variável aleatória uniforme</strong> em \(\Sigma\) é a variável aleatória em que cada estado tem chances iguais de ser realizado. Ou seja, nesse caso de \(N\) estados, temos</p>
\[
\mathbb{P}(X = k) = \frac{1}{N}, \quad \forall k = 1, 2, \ldots, N.
\]
<p>Nesse caso, podemos escrever</p>
\[
X \sim \textrm{Uniforme}(1, 2, \ldots, N),
\]
<p>onde \(\textrm{Uniforme}(\Sigma) = \textrm{Uniforme}(\{1, 2, \ldots, N\})\) é a distribuição uniforme em \(\Sigma = \{1, 2, \ldots, N\}\).</p>
<h2 id="teste_de_bernoulli"><a href="#teste_de_bernoulli" class="header-anchor">Teste de Bernoulli</a></h2>
<p>Uma <strong>variável aleatória de Bernoulli</strong> com parâmetro \(p\), \(0\leq p \leq 1\), possui dois resultados possíveis, \(0\) e \(1\), com probabilidades \(p\) e \(1-p\), respectivamente. Ou seja, \(J = 2\), \(x_1 = 0\), \(x_2 = 1\), \(p_1 = p\) e \(p_2 = 1 - p\). Pode ser exemplificado como o resultado do lançamento de uma moeda, com \(1\) e \(0\) representando &quot;cara&quot; e &quot;coroa&quot;, respectivamente. O resultado de um exame de laboratório verificando a presença de um marcador para alguma doença pode ser &quot;positivo&quot; ou &quot;negativo&quot;, podendo, também, ser modelado por uma variável de Bernoulli.</p>
<p>Denotamos a distribuição de Bernoulli com probabilidade de sucesso \(p\) &#40;e.g. \(\mathbb{P}(X = 1) = p\)&#41; por \(\mathrm{Bernoulli}(p)\). Assim, uma variável aleatória de Bernouille é indicada por</p>
\[
X \sim \mathrm{Bernoulli}(p).
\]

<img src="/notas_sde/assets/pages/c02/exemplos_va_discretas/code/output/pmfbernoulli.svg" alt="">

<img src="/notas_sde/assets/pages/c02/exemplos_va_discretas/code/output/pmfbernoullicum.svg" alt="">
<h2 id="número_de_sucessos_e_a_distribuição_binomial"><a href="#número_de_sucessos_e_a_distribuição_binomial" class="header-anchor">Número de sucessos e a distribuição binomial</a></h2>
<p>Podemos, também, jogar uma moeda \(n\) vezes e contarmos o número de vezes em que o resultado é &quot;cara&quot;, por exemplo. A probabilidade de não termos nenhuma cara é \(1/2^n\), pois devemos ter exatamente \(n\) coroas lançadas, sendo que cada uma tem probabilidade 1/2 de ocorrer. A probabilidade de termos exatamente uma cara é \(n/2^n\), pois a cara pode vir em qualquer um dos \(n\) lançamentos. Mais geralmente, temos um número</p>
\[
  \left(\begin{matrix} n \\ i \end{matrix}\right) = \frac{n!}{i!(n-i)!}
\]
<p>de combinações possíveis de exatamente \(i\) resultados iguais &#40;e.g. &quot;caras&quot;&#41;, em \(n\) lançamentos. Assim, se \(X\) é a variável aleatória contando o número de &quot;caras&quot; em \(n\) lançamentos, então a probabilidade de termos \(i\) caras é</p>
\[
  \mathbb{P}(X = i) = \frac{1}{2^n} \left(\begin{matrix} n \\ i \end{matrix}\right), \quad 1 \leq i \leq n.
\]
<p>No caso de um dado viciado, ou, mais geralmente, de \(n\) testes de Bernoulli com parâmetro \(p\), \(0\leq p \leq 1\), então a probabilidade de \(i\) sucessos é</p>
\[
  \mathbb{P}(X = i) = p^i(1-p)^{n-i} \left(\begin{matrix} n \\ i \end{matrix}\right), \quad 1 \leq i \leq n.
\]
<p>Denotamos essa distribuição binomial por \(B(n, p)\). Assim,</p>
\[
X \sim B(n, p).
\]

<img src="/notas_sde/assets/pages/c02/exemplos_va_discretas/code/output/pmfbinomial.svg" alt="">

<img src="/notas_sde/assets/pages/c02/exemplos_va_discretas/code/output/pmfbinomialcum.svg" alt="">
<h2 id="tempo_de_espera_e_a_distribuição_geométrica"><a href="#tempo_de_espera_e_a_distribuição_geométrica" class="header-anchor">Tempo de espera e a distribuição geométrica</a></h2>
<p>Baseado no teste de Bernoulli, podemos considerar a variável aleatória que nos dá as chances de termos sucesso após \(n\) tentativas frustradas. Ou seja, em \(n\) tentativas, temos insucesso nos primeiros \(n-1\) testes e sucesso apenas no último teste. Se a chance de sucesso é \(p\) e a de fracasso é \(1-p\), com \(0 < p \leq 1\), então temos probabilidade \((1-p)^{n-1}\) de insucessos nos \(n\) primeiros testes e \(p\) de sucesso no último teste, ou seja,</p>
\[
\mathbb{P}(X = n) = (1-p)^{n-1}p
\]
<p>Essa distribuição é chamada de distribuição geométrica. Note que</p>
\[
  \sum_{n=1}^\infty (1-p)^{n-1}p = p + (1-p)p + (1-p)^2p + \ldots = p(1 + (1-p) + (1-p)^2 + \ldots) = p \frac{1}{p} = 1.
\]
<p>Observe que há uma questão de interpretação, aqui. A probabilidade \((1-p)^{n-1}p\) de termos sucesso <em>apenas</em> no \(n\)-ésimo é a mesma que a de termos apenas um sucesso em \(n\) testes, independentemente de ser no último teste ou não.</p>
<p>Observe, ainda, que no caso da distribuição binomial discutida acima, fixamos o número \(n\) de testes e analisamos a quantidade de sucessos nesses \(n\) testes. Já na distribuição geométrica, podemos ter um número arbitrário de testes.</p>

<img src="/notas_sde/assets/pages/c02/exemplos_va_discretas/code/output/pmfgeometrica.svg" alt="">

<img src="/notas_sde/assets/pages/c02/exemplos_va_discretas/code/output/pmfgeometricacum.svg" alt="">
<p>A distribuição geométrica é a única distribuição enumerável &quot;sem memória&quot;. Ou seja, se \(\mathbb{P}\) é uma probabilidade cujo espaço de eventos é \(\Sigma = \mathbb{N}\) e é tal que</p>
\[
\mathbb{P}(X \geq m + n | X \geq m) = \mathbb{P}(X \geq n), \qquad \forall m, n \in \mathbb{N},
\]
<p>então \(\mathbb{P}(X = n)\) é a distribuição geométrica</p>
\[
\mathbb{P}(X = n) = (1 - p)^{n-1}p,
\]
<p>onde</p>
\[
p = \mathbb{P}(X = 1).
\]
<p>A demonstração desse fato faz uso da fórmula para distribuição condicionada</p>
\[
\mathbb{P}(X > m + n | X > m) = \frac{\mathbb{P}(\{X > m + n\} \cap \{X > m\})}{\mathbb{P}(X > m)}.
\]
<p>Como \(n \geq 1\), temos \(\{X > m + n\} \subset \{X > m\}\), de modo que</p>
\[
\mathbb{P}(X > n) = \mathbb{P}(X > m + n | X > m) = \frac{\mathbb{P}(X > m + n)}{\mathbb{P}(X > m)}.
\]
<p>Ou seja,</p>
\[
\mathbb{P}(X > m + n) = \mathbb{P}(X > n)\mathbb{P}(X > m).
\]
<p>Em particular, temos a recursão</p>
\[
\mathbb{P}(X > n + 1) = \mathbb{P}(X > n)\mathbb{P}(X > 1),
\]
<p>cuja solução é</p>
\[
\mathbb{P}(X > n) = \mathbb{P}(X > 1)^n.
\]
<p>Além disso, como \(\Sigma = \mathbb{N}\) e definindo \(p = \mathbb{P}(X = 1)\), temos</p>
\[
\mathbb{P}(X > 1) = 1 - \mathbb{P}(X = 1) = 1 - p.
\]
<p>Portanto,</p>
\[
\mathbb{P}(X > n) = (1 - p)^n.
\]
<p>Daí, tiramos que</p>
\[
\mathbb{P}(X = 1) = \mathbb{P}(X < 1) = 1 - \mathbb{P}(X \geq 2) = 1 - p
\]
<p>e, para \(n = 2, \ldots,\)</p>
\[
\mathbb{P}(X = n) = \mathbb{P}(X > n) - \mathbb{P}(X > n - 1) = (1 - p)^n - (1 - p)^{n - 1} = (1 - p)^{n - 1}(1 - p - 1) = (1 - p)^{n - 1}p.
\]
<p>Assim, obtemos a distribuição geométrica</p>
\[
\mathbb{P}(X = n) = (1 - p)^{n - 1}p, \qquad \forall n\in \mathbb{N}.
\]

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/exemplos_va_continuas"><kbd>→</kbd> 2.3. Variáveis aleatórias contínuas</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: July 06, 2022. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    
        <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>
    

  </body>
</html>
